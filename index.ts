import { Type } from "@sinclair/typebox";
import { Text } from "@mariozechner/pi-tui";
import * as fs from "node:fs";
import * as path from "node:path";
import * as os from "node:os";
import * as crypto from "node:crypto";

// === é…ç½®ä¸å¸¸é‡ ===
const GLOBAL_MEMORY_DIR = path.join(os.homedir(), ".pi-hippocampus");
const DB_PATH = path.join(GLOBAL_MEMORY_DIR, "hippocampus.db");
const CACHE_DIR = path.join(GLOBAL_MEMORY_DIR, ".cache");

const CONFIG = {
  embeddingModel: "Xenova/nomic-embed-text-v1",
  embeddingDimensions: 768,
  maxDistance: 1.2,
  maxMemories: 500,
  defaultDecayRate: 0.05,
  consolidation: {
    minFragmentsForMerge: 2,
    similarityThreshold: 0.75,
    autoPromoteAccessCount: 3,
    fragmentMaxAgeDays: 7,
  },
  context: {
    recentProjectDays: 7,
    staleProjectDays: 30,
    recentProjectFactor: 0.7,
    staleProjectFactor: 0.3,
    alienBreakthroughFactor: 0.8,
  },
  spreading: {
    maxHops: 1,
    minLinkStrength: 0.5,
    spreadDecay: 0.7,
  },
  
  // V5.6.0 å¯åŠ¨å”¤é†’é…ç½® (Startup Recall)
  startupRecall: {
    enabled: true,                    // æ˜¯å¦å¼€å¯å¯åŠ¨å”¤é†’
    lookbackHours: 24,                // å›æº¯æ—¶é—´çª—å£ï¼ˆå°æ—¶ï¼‰
    minImportance: 8,                 // æ ¸å¿ƒè®°å¿†çš„æœ€å°æƒé‡é˜ˆå€¼
    maxTokens: 8000,                  // Token ç¡¬é™åˆ¶ï¼ˆæ—  Ollama æ—¶ï¼‰
    maxMemories: 50,                  // æœ€å¤§è®°å¿†æ¡æ•°ï¼ˆç¡¬é™åˆ¶ï¼‰
    useLLMSummary: true,              // æœ‰ Ollama æ—¶ç”Ÿæˆå‹ç¼©æ‘˜è¦ï¼ˆé»˜è®¤å…³é—­ï¼Œå¯æ‰‹åŠ¨å¼€å¯ï¼‰
    summaryMaxTokens: 500,            // æ‘˜è¦æœ€å¤§ Token æ•°
  },
  
  // V5.6.0 æ™ºèƒ½æ£€ç´¢é…ç½® (RAG with Rerank)
  ragSearch: {
    enabled: true,                    // æ˜¯å¦å¼€å¯æ™ºèƒ½æ£€ç´¢
    vectorSearchLimit: 100,           // å‘é‡æœç´¢æ•°é‡ï¼ˆç¬¬ä¸€é˜¶æ®µï¼‰
    rerankWithLLM: true,              // ä½¿ç”¨æœ¬åœ° LLM é‡æ’åºï¼ˆé»˜è®¤å…³é—­ï¼Œå› ä¸ºä¼šå¯¼è‡´æ¯æ¬¡å¯¹è¯å»¶è¿Ÿï¼‰
    rerankOutputLimit: 10,            // é‡æ’åè¾“å‡ºæ•°é‡
    hardLimitNoLLM: 20,               // æ—  Ollama æ—¶çš„ç¡¬æˆªæ–­æ•°é‡
    includeGlobalCore: true,          // æ˜¯å¦å¼ºåˆ¶åŒ…å«å…¨å±€æ ¸å¿ƒè®°å¿†
    globalCoreMinImportance: 7,       // å…¨å±€æ ¸å¿ƒè®°å¿†çš„æœ€å°é‡è¦æ€§
    globalCoreLimit: 5,               // å…¨å±€æ ¸å¿ƒè®°å¿†æ•°é‡é™åˆ¶
    queryEnhancement: true,           // ä½¿ç”¨æœ¬åœ° LLM å¢å¼ºçŸ­æŸ¥è¯¢ï¼ˆé»˜è®¤å…³é—­ï¼Œä¼šå¢åŠ å»¶è¿Ÿï¼‰
    queryEnhancementThreshold: 20,    // æ¶ˆæ¯é•¿åº¦ä½äºæ­¤å€¼æ—¶è§¦å‘æŸ¥è¯¢å¢å¼º
  },
  
  // V5.4.1 æœ¬åœ° LLM åˆ†æé…ç½® (Enhanced)
  localLLM: {
    enabled: true,                    // Enable local LLM analysis
    provider: 'ollama' as const,      // Currently only supports Ollama
    baseUrl: 'http://localhost:11434',
    model: 'auto',                    // Auto-detects best available model (e.g., qwen2.5, llama3)
    timeout: 20000,                   // Timeout (ms) - Increased to 20s for CPU inference/cold boot
    fallbackToRegex: true,            // Fall back to regex if LLM is unavailable
    maxInputLength: 2000,             // Max input length - Increased for better context awareness
    
    // Model parameters
    temperature: 0,                   // 0 = deterministic
    maxTokens: 256,                   // Limit output length
    
    // Thresholds
    minImportanceToSave: 3,           // Skip if importance is below this
    confidenceThreshold: 0.7,         // LLM confidence threshold (reserved)
    
    // Output control
    preferUserContent: true,          // true = save original user text, false = save LLM summary
    maxContentLength: 200,            // Max content length
    
    // Exclude rules
    excludePatterns: [
      /^(å¥½çš„|ok|å—¯|å“¦|è°¢è°¢|thanks|thank you|got it|understood|æ˜ç™½|æ”¶åˆ°)[\s,!.ã€‚ï¼]*/i,
      /^(å¸®æˆ‘|è¯·|help me|can you|could you)/i,
    ],
    
    // Sensitive information filtering
    sensitivePatterns: [
      /password\s*[:=]/i,
      /å¯†ç \s*[:=ï¼š]/i,
      /api[_-]?key\s*[:=]/i,
      /secret\s*[:=]/i,
      /token\s*[:=]/i,
      /credential/i,
      /private[_-]?key/i,
      /-----BEGIN/i,
      /ghp_[a-zA-Z0-9]{20,}/i,        // GitHub token
      /sk-[a-zA-Z0-9]{20,}/i,         // OpenAI key
      /AKIA[A-Z0-9]{16}/i,            // AWS key
      /xox[baprs]-[a-zA-Z0-9-]+/i,    // Slack token
    ],
    
    // Prompt template config
    promptStyle: 'concise' as 'concise' | 'detailed',  // Concise is better for small models
    language: 'auto' as 'auto' | 'zh' | 'en',          // Output language
  },
  
  // V5.4.1 è‡ªåŠ¨ç¼–ç é…ç½® (æ­£åˆ™å›é€€æ–¹æ¡ˆ)
  autoEncode: {
    enabled: true,
    minMessageLength: 0, // æœæ€»æŒ‡ç¤ºï¼š0é—¨æ§›ï¼Œå…¨é‡åˆ†æ
    
    // ========== ä¿®æ­£/çº é”™æ¨¡å¼ (æ–°å¢) ==========
    // è¿™ç§ä¿¡æ¯ä»·å€¼æé«˜ï¼Œé€šå¸¸æ˜¯å¯¹é”™è¯¯è®¤çŸ¥çš„ä¿®æ­£
    correctionPatterns: [
      // ä¸­æ–‡
      /ä¸å¯¹|é”™äº†|æé”™äº†|å¼„é”™äº†|ä¸æ˜¯.*è€Œæ˜¯/i,
      /å…¶å®æ˜¯|å®é™…ä¸Šæ˜¯|åº”è¯¥æ˜¯|å‡†ç¡®è¯´æ˜¯/i,
      /æ›´æ­£ä¸€ä¸‹|ä¿®æ­£ä¸€ä¸‹|æ”¹ä¸€ä¸‹/i,
      
      // è‹±æ–‡
      /incorrect|wrong|mistake|not.*but/i,
      /actually|in fact|should be|meant to say/i,
      /correction|let me correct/i,
    ],

    // ========== è®¡åˆ’/æ„¿æ™¯æ¨¡å¼ (æ–°å¢) ==========
    // æ•æ‰æœªæ¥çš„è§„åˆ’å’Œç›®æ ‡
    goalPatterns: [
      // ä¸­æ–‡
      /è®¡åˆ’|æ‰“ç®—|å‡†å¤‡|æƒ³è¦|å¸Œæœ›|ç›®æ ‡/i,
      /ä¸‹ä¸€æ­¥|æ¥ä¸‹æ¥|æœªæ¥|roadmap|é‡Œç¨‹ç¢‘/i,
      /é•¿æœŸæ¥çœ‹|æœ€ç»ˆæ•ˆæœ|æ„¿æ™¯/i,
      
      // è‹±æ–‡
      /plan to|going to|intend to|aim to|goal is/i,
      /next step|roadmap|milestone|future/i,
      /long term|vision|ultimate goal/i,
    ],

    // ========== å®šä¹‰/æ¦‚å¿µæ¨¡å¼ (æ–°å¢) ==========
    // æ•æ‰ç”¨æˆ·å¯¹ç‰¹å®šæ¦‚å¿µçš„è§£é‡Š
    definitionPatterns: [
      // ä¸­æ–‡
      /æ‰€è°“.*å°±æ˜¯|.*æ˜¯æŒ‡|.*çš„æ„æ€æ˜¯/i,
      /å®šä¹‰ä¸º|ç†è§£ä¸º|çœ‹ä½œæ˜¯/i,
      
      // è‹±æ–‡
      /means that|refers to|defined as/i,
      /is essentially|basically is/i,
    ],
    
    // ========== è§„åˆ™/åå¥½æ¨¡å¼ (æ‰©å……) ==========
    // ç”¨æˆ·è¡¨è¾¾ä¸ªäººåå¥½ã€ç¼–ç è§„èŒƒã€å·¥ä½œæµç¨‹æ—¶è§¦å‘
    rulePatterns: [
      // ä¸­æ–‡ï¼šç¦æ­¢/å¿…é¡»ç±»
      /ä¸è¦|ä¸ç”¨|åˆ«ç”¨|ç¦æ­¢|ä¸è®¸|ä¸èƒ½|ä¸å¯ä»¥|ä¸¥ç¦|é¿å…|æœç»/i,
      /å¿…é¡»|ä¸€å®šè¦|åŠ¡å¿…|è¦æ±‚|å¼ºåˆ¶|åªèƒ½|åªç”¨|åªå‡†/i,
      /åˆ«æ•´|åˆ«æ|å°‘å¼„|åˆ«ç»™æˆ‘/i, // å£è¯­åŒ–
      
      // ä¸­æ–‡ï¼šåå¥½ç±»
      /åå¥½|å–œæ¬¢|ä¹ æƒ¯|å€¾å‘|æ›´æ„¿æ„|æ¯”è¾ƒå–œæ¬¢|æˆ‘è§‰å¾—.*å¥½/i,
      /è®¨åŒ|ä¸å–œæ¬¢|åæ„Ÿ|çƒ¦|å—ä¸äº†|æ¶å¿ƒ|éš¾ç”¨/i,
      /ä¸€èˆ¬|é€šå¸¸|å¹³æ—¶|å¾€å¾€|å¤§å¤šæ•°æ—¶å€™/i, // ä¹ æƒ¯
      
      // ä¸­æ–‡ï¼šæ—¶é—´æ ‡è®°ï¼ˆè¡¨ç¤ºæŒä¹…è§„åˆ™ï¼‰
      /ä»¥å|ä»Šå|ä»ç°åœ¨èµ·|ä¹‹åéƒ½|ä»¥åéƒ½|æ°¸è¿œ|ä¸€ç›´/i,
      /è®°ä½|è®°å¾—|åˆ«å¿˜äº†|æé†’æˆ‘|åˆ»åœ¨DNAé‡Œ/i,
      
      // ä¸­æ–‡ï¼šè§„èŒƒ/æ ‡å‡†ç±»
      /è§„èŒƒ|æ ‡å‡†|çº¦å®š|æƒ¯ä¾‹|é£æ ¼|æ ¼å¼|å‘½å/i,
      /ç»Ÿä¸€ç”¨|ç»Ÿä¸€ä½¿ç”¨|ä¸€å¾‹|å…¨éƒ¨ç”¨|éƒ½ç”¨/i,
      /æœ€ä½³å®è·µ|best practice|åŸåˆ™/i,
      
      // è‹±æ–‡ï¼šProhibition/Must
      /don't|dont|do not|never|avoid|stop using|quit/i,
      /must|always|shall|should|have to|need to|required/i,
      // è‹±æ–‡ï¼šPreference
      /prefer|like to|rather|better to|fan of|love using/i,
      /hate|dislike|can't stand|annoying/i,
      /usually|typically|generally|habit/i,
      // è‹±æ–‡ï¼šTime markers
      /from now on|going forward|in the future|from here on/i,
      /remember|keep in mind|don't forget|note that/i,
      // è‹±æ–‡ï¼šStandards
      /convention|standard|pattern|style guide|best practice/i,
      /always use|stick to|follow the|principle/i,
    ],
    
    // ========== äº‹å®/é…ç½®æ¨¡å¼ (æ‰©å……) ==========
    // æŠ€æœ¯æ ˆã€é…ç½®ä¿¡æ¯ã€ç¯å¢ƒå˜é‡ç­‰
    factPatterns: [
      // ä¸­æ–‡ï¼šæŠ€æœ¯æ ˆ
      /ç”¨çš„æ˜¯|ä½¿ç”¨çš„æ˜¯|åŸºäº|é‡‡ç”¨|æŠ€æœ¯æ ˆ|æ¡†æ¶æ˜¯/i,
      /ç‰ˆæœ¬|v\d+|@\d+/i,
      /ä¾èµ–|åº“|package|åŒ…/i,
      
      // ä¸­æ–‡ï¼šé…ç½®
      /é…ç½®|è®¾ç½®|å‚æ•°|é€‰é¡¹|ç¯å¢ƒå˜é‡|env/i,
      /åœ°å€|è·¯å¾„|ç›®å½•|æ–‡ä»¶å¤¹|ä½ç½®|path/i,
      /ç«¯å£|port|host|åŸŸå|url|uri|é“¾æ¥/i,
      
      // ä¸­æ–‡ï¼šå‡­è¯ï¼ˆæ³¨æ„ï¼šè‡ªåŠ¨ç¼–ç æ—¶ä¼šè·³è¿‡æ•æ„Ÿä¿¡æ¯ï¼‰
      /è´¦å·|ç”¨æˆ·å|user|id/i,
      // (å¯†ç /keyç­‰æ•æ„Ÿè¯ç”±è¿‡æ»¤å™¨å¤„ç†ï¼Œè¿™é‡ŒåªåŒ¹é…éæ•æ„Ÿæè¿°)
      
      // ä¸­æ–‡ï¼šæ•°æ®åº“/å­˜å‚¨
      /æ•°æ®åº“|database|db|mysql|postgres|mongo|redis|sqlite/i,
      /è¡¨å|å­—æ®µ|schema|é›†åˆ|collection|å­˜å‚¨/i,
      /s3|oss|bucket|å­˜å‚¨æ¡¶/i,
      
      // ä¸­æ–‡ï¼šéƒ¨ç½²/ç¯å¢ƒ
      /æœåŠ¡å™¨|server|vps|äº‘|aws|azure|gcp|é˜¿é‡Œäº‘|è…¾è®¯äº‘/i,
      /ç¯å¢ƒ|environment|dev|prod|staging|test/i,
      /docker|å®¹å™¨|k8s|kubernetes|nginx|pm2/i,
      /ci|cd|æµæ°´çº¿|pipeline|action/i,
      
      // è‹±æ–‡ï¼šTech stack
      /using|powered by|built with|based on|running on/i,
      /version|v\d+\.\d+|dependency|lib/i,
      // è‹±æ–‡ï¼šConfiguration
      /config|setting|option|parameter|env var/i,
      /path|directory|folder|location|file/i,
      /port|host|domain|url|endpoint/i,
      // è‹±æ–‡ï¼šInfrastructure
      /server|instance|container|cluster|node/i,
      /deployed on|hosted on|running on/i,
      /database|db|store|storage/i,
    ],
    
    // ========== äº‹ä»¶æ¨¡å¼ ==========
    // å®Œæˆçš„ä»»åŠ¡ã€è§£å†³çš„é—®é¢˜ã€é‡Œç¨‹ç¢‘
    eventPatterns: [
      // ä¸­æ–‡ï¼šå®Œæˆç±»
      /å®Œæˆäº†|æå®šäº†|åšå®Œäº†|å¼„å¥½äº†|å®ç°äº†|å†™å®Œäº†/i,
      /æˆåŠŸ|okäº†|å¯ä»¥äº†|æ²¡é—®é¢˜äº†|é€šè¿‡äº†/i,
      // ä¸­æ–‡ï¼šä¿®å¤ç±»
      /ä¿®å¤äº†|ä¿®å¥½äº†|è§£å†³äº†|å¤„ç†äº†|æå®š.*bug|fix.*äº†/i,
      /ç»ˆäº.*äº†|èŠ±äº†.*æ—¶é—´|æŠ˜è…¾.*ä¹…/i,
      // ä¸­æ–‡ï¼šéƒ¨ç½²/å‘å¸ƒ
      /éƒ¨ç½²äº†|å‘å¸ƒäº†|ä¸Šçº¿äº†|æ¨é€äº†|æäº¤äº†|åˆå¹¶äº†/i,
      /deploy|release|publish|push|merge|commit/i,
      // ä¸­æ–‡ï¼šé—®é¢˜/è¸©å‘
      /è¸©å‘|è¸©äº†.*å‘|é‡åˆ°.*é—®é¢˜|ç¢°åˆ°.*bug/i,
      /æŠ¥é”™|error|å¼‚å¸¸|exception|å¤±è´¥|fail/i,
      /åŸæ¥æ˜¯|å‘ç°æ˜¯|é—®é¢˜åœ¨äº|æ ¹æœ¬åŸå› /i,
      // ä¸­æ–‡ï¼šå­¦ä¹ /å‘ç°
      /å­¦åˆ°äº†|å‘ç°äº†|åŸæ¥|æ‰çŸ¥é“|æ²¡æƒ³åˆ°/i,
      /æŠ€å·§|çªé—¨|è¯€çª|æ–¹æ³•|æ€è·¯/i,
      
      // è‹±æ–‡ï¼šCompletion
      /finished|completed|done with|wrapped up|shipped/i,
      /works now|working now|succeeded|passed/i,
      // è‹±æ–‡ï¼šFixing
      /fixed|resolved|solved|patched|debugged/i,
      /finally|after.*hours|took.*to figure out/i,
      // è‹±æ–‡ï¼šDeployment
      /deployed|released|published|pushed|merged/i,
      /went live|in production|rolled out/i,
      // è‹±æ–‡ï¼šProblems
      /ran into|encountered|hit a|stumbled upon/i,
      /bug|error|issue|problem|crash|exception/i,
      /turns out|realized|figured out|root cause/i,
      // è‹±æ–‡ï¼šLearning
      /learned|discovered|found out|til:|today i learned/i,
      /trick|tip|hack|workaround|solution/i,
    ],
    
    // ========== èº«ä»½/ä¸ªäººä¿¡æ¯æ¨¡å¼ ==========
    // ç”¨æˆ·çš„ä¸ªäººä¿¡æ¯ã€èº«ä»½ã€è”ç³»æ–¹å¼
    identityPatterns: [
      // ä¸­æ–‡
      /æˆ‘æ˜¯|æˆ‘å«|æˆ‘çš„åå­—|æœ¬äºº|æˆ‘è‡ªå·±/i,
      /æˆ‘çš„.*æ˜¯|æˆ‘.*ä½åœ¨|æˆ‘åœ¨.*å·¥ä½œ/i,
      /ç”µè¯|æ‰‹æœº|é‚®ç®±|email|å¾®ä¿¡|qq/i,
      /ç”Ÿæ—¥|å¹´é¾„|å²/i,
      
      // è‹±æ–‡
      /my name is|i am|i'm called|call me/i,
      /i live in|i work at|i'm from/i,
      /my.*is|my phone|my email/i,
    ],
    
    // ========== é¡¹ç›®ä¿¡æ¯æ¨¡å¼ ==========
    // å½“å‰é¡¹ç›®çš„å…³é”®ä¿¡æ¯
    projectPatterns: [
      // ä¸­æ–‡
      /è¿™ä¸ªé¡¹ç›®|æœ¬é¡¹ç›®|å½“å‰é¡¹ç›®|è¿™ä¸ªä»“åº“|è¿™ä¸ªrepo/i,
      /é¡¹ç›®å|é¡¹ç›®å«|repoå/i,
      /ä¸»è¦åŠŸèƒ½|æ ¸å¿ƒåŠŸèƒ½|ç”¨æ¥åš|ç›®çš„æ˜¯/i,
      /æ¶æ„|ç»“æ„|ç›®å½•ç»“æ„|æ–‡ä»¶ç»“æ„/i,
      // ä¸­æ–‡ï¼šè¯é¢˜ç„¦ç‚¹ï¼ˆæ–°å¢ï¼‰
      /.*çš„äº‹|å…³äº.*|.*å¼€å‘|.*è®¡åˆ’|.*ä»»åŠ¡|.*ç›®æ ‡/i,
      /æ­£åœ¨å¼„|æ­£åœ¨æ|å¤„ç†.*|è§£å†³.*/i,
      
      // è‹±æ–‡
      /this project|this repo|current project/i,
      /project name|repo name|codebase/i,
      /main feature|core function|purpose is|used for/i,
      /architecture|structure|layout/i,
      // è‹±æ–‡ï¼šTopic Focus (New)
      /working on|focusing on|dealing with|regarding/i,
    ],
  }
};

// === è¾…åŠ©å‡½æ•° ===
function getProjectHash(cwd: string): string {
  return crypto.createHash("md5").update(cwd).digest("hex");
}

function ensureDir(dir: string) {
  if (!fs.existsSync(dir)) fs.mkdirSync(dir, { recursive: true });
}

// === V5.4.1 æœ¬åœ° LLM åˆ†æå™¨ (Enhanced) ===
let ollamaAvailable: boolean | null = null;
let lastOllamaStatus: boolean | null = null;  // è¿½è¸ªä¸Šæ¬¡çŠ¶æ€ï¼Œç”¨äºæ£€æµ‹å˜åŒ–
let uiContext: any = null;  // ä¿å­˜ ctx.ui å¼•ç”¨ï¼Œç”¨äºå®æ—¶é€šçŸ¥
let currentLLMMode: string = 'Regex';  // å½“å‰æ¨¡å¼ï¼šæ¨¡å‹åæˆ– 'Regex'
let lastRecallCount: number = 0;  // ä¸Šæ¬¡å¬å›æ•°é‡

// æ›´æ–°åº•éƒ¨çŠ¶æ€æ ï¼ˆåˆå¹¶æ˜¾ç¤ºï¼‰
const STATUS_VERSION = "v5.7.1";
function updateStatusBar(ctx: any) {
  const modelDisplay = currentLLMMode === 'Regex' ? 'Regex' : currentLLMMode;
  const recallText = lastRecallCount >= 1000 ? '999+' : lastRecallCount.toString();
  const recallDisplay = lastRecallCount > 0 ? ` | Recall: ${recallText}` : '';
  // ç®€åŒ–çŠ¶æ€æ˜¾ç¤ºï¼Œé¿å…å¤ªé•¿
  const displayVersion = STATUS_VERSION.replace('v', '');
  ctx.ui.setStatus("hippocampus", `ğŸ§  ${displayVersion} ${modelDisplay}${recallDisplay}`);
}

interface LocalLLMAnalysisResult {
  should_save: boolean;
  type: 'fact' | 'rule' | 'event';
  importance: number;
  scope: 'global' | 'local';
  content: string;
  tags: string[];
  reason: string;
}

// æ£€æµ‹ Ollama æ˜¯å¦å¯ç”¨ï¼ˆå®æ—¶æ£€æµ‹ï¼Œä¸ç¼“å­˜ï¼‰
async function checkOllamaAvailable(forceRefresh: boolean = false): Promise<boolean> {
  if (!forceRefresh && ollamaAvailable !== null) return ollamaAvailable;
  
  try {
    const controller = new AbortController();
    const timeoutId = setTimeout(() => controller.abort(), 2000);
    
    // Request /api/tags to get model list
    const response = await fetch(`${CONFIG.localLLM.baseUrl}/api/tags`, {
      signal: controller.signal
    });
    
    clearTimeout(timeoutId);
    
    if (response.ok) {
      ollamaAvailable = true;
      
      // Auto-detect model if set to 'auto'
      if (CONFIG.localLLM.model === 'auto') {
        try {
          const data = await response.json();
          const models = (data.models || []).map((m: any) => m.name);
          
          // Filter out embedding models to avoid selecting them for chat
          const chatModels = models.filter((m: string) => !m.includes('embed') && !m.includes('nomic'));
          
          if (chatModels.length > 0) {
            // Priority list for Chinese/Coding context
            const priorities = ['qwen2.5', 'deepseek', 'llama3', 'mistral', 'qwen', 'gemma'];
            
            let selected = '';
            for (const p of priorities) {
              const match = chatModels.find((m: string) => m.toLowerCase().includes(p));
              if (match) {
                selected = match;
                break;
              }
            }
            
            // Fallback to first available chat model
            if (!selected) selected = chatModels[0];
            
            CONFIG.localLLM.model = selected;
            console.log(`[Hippocampus] Auto-selected model: ${selected}`);
            
            // Update mode display immediately if waiting
            if (currentLLMMode === 'Regex') currentLLMMode = selected;
          }
        } catch (e) {
          // JSON parse failed, keep 'auto'
        }
      }
      
      return true;
    } else {
      ollamaAvailable = false;
      return false;
    }
  } catch (e) {
    ollamaAvailable = false;
    return false;
  }
}

// æ£€æµ‹å¹¶é€šçŸ¥ Ollama çŠ¶æ€å˜åŒ– (v5.7.0: é™é»˜æ¨¡å¼ï¼Œç§»é™¤ Warning)
async function checkAndNotifyOllamaStatus(ctx: any): Promise<boolean> {
  const currentStatus = await checkOllamaAvailable(true);
  
  // æ£€æµ‹çŠ¶æ€å˜åŒ–
  if (lastOllamaStatus !== null && currentStatus !== lastOllamaStatus) {
    if (currentStatus) {
      // ä»ç¦»çº¿å˜ä¸ºåœ¨çº¿ï¼šæç¤ºä¸€ä¸‹ï¼ˆå¥½äº‹å¯ä»¥ç®€å•æç¤ºï¼‰
      currentLLMMode = CONFIG.localLLM.model;
      // ctx.ui.notify(`ğŸ§  LLM Connected: ${CONFIG.localLLM.model}`, "success");
    } else {
      // ä»åœ¨çº¿å˜ä¸ºç¦»çº¿ï¼šé™é»˜é™çº§ï¼Œä¸æ‰“æ‰°ç”¨æˆ·
      currentLLMMode = 'Regex';
      console.log(`[Hippocampus] LLM disconnected, silently falling back to Regex`);
      // ç§»é™¤è­¦å‘Šå¼¹çª—
      // ctx.ui.notify(`âš ï¸ LLM disconnected, using Regex`, "warning");
    }
    updateStatusBar(ctx);
  }
  
  lastOllamaStatus = currentStatus;
  return currentStatus;
}

// æ£€æµ‹è¯­è¨€
function detectLanguage(text: string): 'zh' | 'en' {
  const chineseChars = text.match(/[\u4e00-\u9fa5]/g) || [];
  return chineseChars.length > text.length * 0.1 ? 'zh' : 'en';
}

// æ£€æŸ¥æ˜¯å¦åŒ¹é…æ’é™¤æ¨¡å¼
function matchesExcludePattern(text: string): boolean {
  return CONFIG.localLLM.excludePatterns.some(pattern => pattern.test(text));
}

// æ£€æŸ¥æ˜¯å¦åŒ…å«æ•æ„Ÿä¿¡æ¯
function hasSensitiveInfo(text: string): boolean {
  return CONFIG.localLLM.sensitivePatterns.some(pattern => pattern.test(text));
}

// V5.4.1 Enhanced: æ„å»ºä¼˜åŒ–çš„åˆ†æ Prompt
function buildAnalysisPrompt(recentHistory: Array<{role: string, content: string}>, lang: 'zh' | 'en'): string {
  // æœæ€»æŒ‡ç¤ºï¼šæä¾›ä¸Šä¸‹æ–‡ï¼Œè®© LLM ç†è§£è¯¸å¦‚ "å¥½" è¿™ç§çŸ­è¯­çš„çœŸå®å«ä¹‰
  
  // å°†å†å²è®°å½•æ ¼å¼åŒ–ä¸ºæ–‡æœ¬
  const conversationText = recentHistory.map(msg => {
    const role = msg.role === 'user' ? (lang === 'zh' ? 'ç”¨æˆ·' : 'User') : (lang === 'zh' ? 'åŠ©æ‰‹' : 'Assistant');
    return `${role}: ${msg.content}`;
  }).join('\n');
  
  if (CONFIG.localLLM.promptStyle === 'concise') {
    return buildConcisePrompt(conversationText, lang);
  } else {
    return buildDetailedPrompt(conversationText, lang);
  }
}

// ç®€æ´ Promptï¼ˆæ¨èç”¨äº 7B æ¨¡å‹ï¼‰
function buildConcisePrompt(conversationText: string, lang: 'zh' | 'en'): string {
  if (lang === 'zh') {
    return `åˆ†æè¿™æ®µå¯¹è¯ï¼Œæå–å€¼å¾—è®°å¿†çš„ä¿¡æ¯ã€‚

ğŸš¨ æœæ€»æŒ‡ç¤ºï¼šç»“åˆä¸Šä¸‹æ–‡ç†è§£ç®€çŸ­å›å¤ï¼ˆå¦‚"å¥½"ã€"è¡Œ"ï¼‰ã€‚å…¨é‡åˆ†æï¼Œæ„å»ºå¤§è„‘è®°å¿†ã€‚

å¯¹è¯å†å²:
${conversationText}

åˆ¤æ–­æ ‡å‡†:
âœ… ä¿å­˜: ç”¨æˆ·åå¥½/è§„åˆ™ã€æŠ€æœ¯é…ç½®ã€å®Œæˆçš„ä»»åŠ¡ã€è¸©å‘ç»éªŒã€å½“å‰å…³æ³¨ç„¦ç‚¹ã€åŸºäºä¸Šä¸‹æ–‡æ¨æ–­å‡ºçš„æ„å›¾
âŒ ä¸ä¿å­˜: çº¯ç²¹çš„å¯’æš„ï¼Œæ— å®é™…æ„ä¹‰çš„ç¡®è®¤ï¼ˆé™¤éä»£è¡¨äº†é‡è¦å†³ç­–ï¼‰

è¾“å‡ºæ ¼å¼(JSON):
{"save":true/false,"type":"rule/fact/event","imp":1-10,"scope":"global/local","content":"åŸºäºä¸Šä¸‹æ–‡çš„å®Œæ•´æ‘˜è¦","tags":["æ ‡ç­¾"]}

ç¤ºä¾‹:
[å¯¹è¯å†å²]
ç”¨æˆ·: æŠŠMAX_BUY_PRICEæ”¹æˆ0.65
åŠ©æ‰‹: å¥½çš„ï¼Œå·²ä¿®æ”¹ã€‚
ç”¨æˆ·: å¥½
[è¾“å‡º]
{"save":true,"type":"event","imp":6,"scope":"local","content":"ç¡®è®¤ä¿®æ”¹ MAX_BUY_PRICE ä¸º 0.65","tags":["é…ç½®","ç­–ç•¥"]}

ç°åœ¨åˆ†æä¸Šé¢çš„å¯¹è¯ï¼Œè¾“å‡ºJSON:`;
  } else {
    return `Analyze conversation history. Extract memories based on context.

Context is KEY. "Ok" might mean "Deploy to Prod" depending on history.

Conversation History:
${conversationText}

Save: preferences, rules, configs, tasks, decisions inferred from context
Skip: empty chitchat

Format (JSON):
{"save":true/false,"type":"rule/fact/event","imp":1-10,"scope":"global/local","content":"Context-aware summary","tags":["tag"]}

Example:
[History]
User: Change MAX_BUY_PRICE to 0.65
Assistant: Done.
User: Good
[Output]
{"save":true,"type":"event","imp":6,"scope":"local","content":"Confirmed change of MAX_BUY_PRICE to 0.65","tags":["config","strategy"]}

Now analyze and output JSON:`;
  }
}

// è¯¦ç»† Promptï¼ˆç”¨äºæ›´å¤§çš„æ¨¡å‹ï¼‰
function buildDetailedPrompt(conversationText: string, lang: 'zh' | 'en'): string {
  return `You are a memory analyzer. Analyze the following CONVERSATION HISTORY to extract long-term memories.

## CRITICAL: Context Awareness
You are provided with a conversation history. You must use this context to interpret short or ambiguous messages like "yes", "no", "do it".
- "Yes" after "Should I deploy?" -> Event: User authorized deployment.
- "No" after "Do you like dark mode?" -> Rule: User dislikes dark mode.

## Conversation History
${conversationText}

## Classification Guide
(Same as before...)

Analyze and output JSON:`;
}

// è°ƒç”¨ Ollama è¿›è¡Œåˆ†æ
async function analyzeWithLocalLLM(recentHistory: Array<{role: string, content: string}>): Promise<LocalLLMAnalysisResult | null> {
  if (!CONFIG.localLLM.enabled) return null;
  
  const lastUserMsg = recentHistory.filter(m => m.role === 'user').pop();
  if (!lastUserMsg) return null;
  
  // å¿«é€Ÿè¿‡æ»¤ï¼šæ’é™¤æ¨¡å¼ (ä»…æ£€æŸ¥æœ€æ–°ä¸€æ¡)
  if (matchesExcludePattern(lastUserMsg.content)) {
    return { should_save: false, type: 'fact', importance: 0, scope: 'local', content: '', tags: [], reason: 'Excluded by pattern' };
  }
  
  // å¿«é€Ÿè¿‡æ»¤ï¼šæ•æ„Ÿä¿¡æ¯
  if (hasSensitiveInfo(lastUserMsg.content)) {
    return { should_save: false, type: 'fact', importance: 0, scope: 'local', content: '', tags: [], reason: 'Contains sensitive info' };
  }
  
  const isAvailable = await checkOllamaAvailable();
  if (!isAvailable) return null;
  
  try {
    const lang = CONFIG.localLLM.language === 'auto' ? detectLanguage(lastUserMsg.content) : CONFIG.localLLM.language;
    const prompt = buildAnalysisPrompt(recentHistory, lang);
    
    const controller = new AbortController();

    const timeoutId = setTimeout(() => controller.abort(), CONFIG.localLLM.timeout);
    
    const response = await fetch(`${CONFIG.localLLM.baseUrl}/api/generate`, {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({
        model: CONFIG.localLLM.model,
        prompt: prompt,
        stream: false,
        options: {
          temperature: CONFIG.localLLM.temperature,
          num_predict: CONFIG.localLLM.maxTokens,
        }
      }),
      signal: controller.signal
    });
    
    clearTimeout(timeoutId);
    
    if (!response.ok) return null;
    
    const data = await response.json();
    const text = data.response?.trim() || '';
    
    // è§£æ JSONï¼ˆå¤„ç†å¯èƒ½çš„ markdown åŒ…è£¹ï¼‰
    let jsonStr = text;
    const jsonMatch = text.match(/\{[\s\S]*\}/);
    if (jsonMatch) {
      jsonStr = jsonMatch[0];
    }
    
    const raw = JSON.parse(jsonStr);
    
    // é€‚é…ç®€åŒ–æ ¼å¼ï¼ˆsave/impï¼‰å’Œæ ‡å‡†æ ¼å¼ï¼ˆshould_save/importanceï¼‰
    const result: LocalLLMAnalysisResult = {
      should_save: raw.save ?? raw.should_save ?? false,
      type: raw.type || 'fact',
      importance: raw.imp ?? raw.importance ?? 3,
      scope: raw.scope || 'local',
      content: raw.content || '',
      tags: raw.tags || [],
      reason: raw.reason || ''
    };
    
    // éªŒè¯å’Œä¿®æ­£
    if (typeof result.should_save !== 'boolean') result.should_save = false;
    if (!['fact', 'rule', 'event'].includes(result.type)) result.type = 'fact';
    if (!['global', 'local'].includes(result.scope)) result.scope = 'local';
    if (!Array.isArray(result.tags)) result.tags = [];
    
    result.importance = Math.max(1, Math.min(10, Number(result.importance) || 3));
    
    // åº”ç”¨é‡è¦æ€§é˜ˆå€¼
    if (result.should_save && result.importance < CONFIG.localLLM.minImportanceToSave) {
      result.should_save = false;
      result.reason = `Importance ${result.importance} below threshold ${CONFIG.localLLM.minImportanceToSave}`;
    }
    
    // å¤„ç†å†…å®¹
    if (result.should_save) {
      if (!result.content || result.content.length < 5) {
        // å¦‚æœ LLM æ²¡æœ‰ç”Ÿæˆå¥½çš„æ‘˜è¦ï¼Œä½¿ç”¨ç”¨æˆ·åŸæ–‡
        result.content = userMessage.substring(0, CONFIG.localLLM.maxContentLength).replace(/\n+/g, ' ').trim();
      } else if (result.content.length > CONFIG.localLLM.maxContentLength) {
        result.content = result.content.substring(0, CONFIG.localLLM.maxContentLength) + '...';
      }
    }
    
    return result;
  } catch (e) {
    // é™é»˜å¤±è´¥ï¼Œå›é€€åˆ°æ­£åˆ™
    return null;
  }
}

// === å»¶è¿ŸåŠ è½½æ¨¡å— ===
let Database: any = null;
let sqliteVec: any = null;
let pipeline: any = null;
let transformersEnv: any = null;
let embeddingPipeline: any = null;
let db: any = null;

async function loadDependencies() {
  if (Database && sqliteVec && pipeline) return;
  const betterSqlite = await import("better-sqlite3");
  Database = betterSqlite.default;
  sqliteVec = await import("sqlite-vec");
  const transformers = await import("@xenova/transformers");
  pipeline = transformers.pipeline;
  transformersEnv = transformers.env;
  transformersEnv.allowLocalModels = true;
  transformersEnv.allowRemoteModels = true;
  transformersEnv.cacheDir = CACHE_DIR;
}

// === æ•°æ®åº“åˆå§‹åŒ– (V5.4.1 Schema) ===
async function initDB() {
  if (db) return db;
  await loadDependencies();
  ensureDir(GLOBAL_MEMORY_DIR);
  db = new Database(DB_PATH);
  sqliteVec.load(db);

  // 1. Memories Table
  db.exec(`
    CREATE TABLE IF NOT EXISTS memories (
      id TEXT PRIMARY KEY,
      content TEXT NOT NULL,
      tags TEXT,
      scope TEXT DEFAULT 'local',
      project_id TEXT,
      status TEXT DEFAULT 'active',
      parent_id TEXT,
      change_reason TEXT,
      source TEXT DEFAULT 'user',
      type TEXT DEFAULT 'fact',
      importance INTEGER DEFAULT 1,
      decay_rate REAL DEFAULT 0.05,
      access_count INTEGER DEFAULT 0,
      last_accessed_at INTEGER,
      created_at INTEGER NOT NULL,
      updated_at INTEGER NOT NULL
    );
  `);

  // 2. Associative Links
  db.exec(`
    CREATE TABLE IF NOT EXISTS memory_links (
      source_id TEXT NOT NULL,
      target_id TEXT NOT NULL,
      type TEXT DEFAULT 'association',
      strength REAL DEFAULT 1.0,
      created_at INTEGER NOT NULL,
      PRIMARY KEY (source_id, target_id)
    );
  `);

  // 3. Vector Table
  db.exec(`
    CREATE VIRTUAL TABLE IF NOT EXISTS vec_memories USING vec0(
      memory_id TEXT PRIMARY KEY,
      embedding FLOAT[${CONFIG.embeddingDimensions}]
    );
  `);

  // 4. Projects Table
  db.exec(`
    CREATE TABLE IF NOT EXISTS projects (
      id TEXT PRIMARY KEY,
      name TEXT,
      path TEXT UNIQUE,
      last_active_at INTEGER NOT NULL,
      created_at INTEGER NOT NULL
    );
  `);

  // 5. V5.4.1 æ–°å¢ï¼šå¯¹è¯ç¼“å†²åŒºï¼ˆç”¨äºè‡ªåŠ¨ç¼–ç åˆ†æï¼‰
  db.exec(`
    CREATE TABLE IF NOT EXISTS conversation_buffer (
      id INTEGER PRIMARY KEY AUTOINCREMENT,
      project_id TEXT NOT NULL,
      role TEXT NOT NULL,
      content TEXT NOT NULL,
      timestamp INTEGER NOT NULL
    );
  `);

  // Schema Migration
  try {
    const tableInfo = db.pragma("table_info(memories)");
    const hasType = tableInfo.some((col: any) => col.name === "type");
    if (!hasType) {
      console.log("ğŸ§  Migrating to V5.4.1...");
      const columns = [
        "ADD COLUMN type TEXT DEFAULT 'fact'",
        "ADD COLUMN importance INTEGER DEFAULT 1",
        "ADD COLUMN decay_rate REAL DEFAULT 0.05"
      ];
      for (const col of columns) {
        try { db.exec(`ALTER TABLE memories ${col};`); } catch (e) {}
      }
    }
  } catch (e) {}

  return db;
}

function closeDB() {
  if (db) {
    try { db.pragma('wal_checkpoint(TRUNCATE)'); db.close(); } catch (e) {}
    db = null;
  }
}

async function getEmbedding(text: string, type: 'query' | 'document' = 'document'): Promise<Float32Array> {
  await loadDependencies();
  if (!embeddingPipeline) {
    embeddingPipeline = await pipeline("feature-extraction", CONFIG.embeddingModel);
  }
  
  let inputText = text;
  if (CONFIG.embeddingModel.includes("nomic")) {
    if (!text.startsWith("search_query:") && !text.startsWith("search_document:")) {
      inputText = type === 'query' ? `search_query: ${text}` : `search_document: ${text}`;
    }
  }

  const output = await embeddingPipeline(inputText, { pooling: "mean", normalize: true });
  return new Float32Array(output.data);
}

// === é¡¹ç›®æ³¨å†Œ ===
async function registerProject(projectId: string, cwd: string) {
  const database = await initDB();
  const now = Date.now();
  const projectName = path.basename(cwd);
  
  database.prepare(`
    INSERT INTO projects (id, name, path, last_active_at, created_at)
    VALUES (?, ?, ?, ?, ?)
    ON CONFLICT(id) DO UPDATE SET last_active_at = ?, name = COALESCE(name, ?)
  `).run(projectId, projectName, cwd, now, now, now, projectName);
}

async function findProjectByName(name: string): Promise<{ id: string; path: string } | null> {
  const database = await initDB();
  const row = database.prepare(`
    SELECT id, path FROM projects 
    WHERE LOWER(name) LIKE ? OR LOWER(path) LIKE ?
    ORDER BY last_active_at DESC LIMIT 1
  `).get(`%${name.toLowerCase()}%`, `%${name.toLowerCase()}%`);
  return row || null;
}

async function getProjectActivity(projectId: string): Promise<'current' | 'recent' | 'stale' | 'unknown'> {
  const database = await initDB();
  const row = database.prepare(`SELECT last_active_at FROM projects WHERE id = ?`).get(projectId);
  if (!row) return 'unknown';
  
  const daysAgo = (Date.now() - row.last_active_at) / (1000 * 60 * 60 * 24);
  if (daysAgo < CONFIG.context.recentProjectDays) return 'recent';
  if (daysAgo < CONFIG.context.staleProjectDays) return 'stale';
  return 'stale';
}

// === V5.4.1 æ ¸å¿ƒï¼šå¯¹è¯ç¼“å†²åŒºç®¡ç† ===
async function bufferConversation(projectId: string, role: string, content: string) {
  const database = await initDB();
  database.prepare(`
    INSERT INTO conversation_buffer (project_id, role, content, timestamp)
    VALUES (?, ?, ?, ?)
  `).run(projectId, role, content, Date.now());
  
  // åªä¿ç•™æœ€è¿‘ 20 æ¡
  database.prepare(`
    DELETE FROM conversation_buffer 
    WHERE project_id = ? AND id NOT IN (
      SELECT id FROM conversation_buffer WHERE project_id = ? ORDER BY timestamp DESC LIMIT 20
    )
  `).run(projectId, projectId);
}

async function getRecentConversation(projectId: string, limit: number = 10): Promise<Array<{role: string, content: string}>> {
  const database = await initDB();
  return database.prepare(`
    SELECT role, content FROM conversation_buffer 
    WHERE project_id = ? 
    ORDER BY timestamp DESC LIMIT ?
  `).all(projectId, limit).reverse();
}

async function clearConversationBuffer(projectId: string) {
  const database = await initDB();
  database.prepare(`DELETE FROM conversation_buffer WHERE project_id = ?`).run(projectId);
}

// === V5.4.1 æ ¸å¿ƒï¼šæ™ºèƒ½è‡ªåŠ¨ç¼–ç åˆ†æå™¨ ===
interface AutoEncodeResult {
  shouldSave: boolean;
  type?: 'fact' | 'event' | 'rule';
  importance?: number;
  scope?: 'global' | 'local';
  content?: string;
  reason?: string;
  tags?: string[];
}

// æ£€æµ‹æ˜¯å¦åŒ¹é…ä»»ä¸€æ¨¡å¼
function matchesAnyPattern(text: string, patterns: RegExp[]): { matched: boolean; pattern?: RegExp } {
  for (const pattern of patterns) {
    if (pattern.test(text)) {
      return { matched: true, pattern };
    }
  }
  return { matched: false };
}

// æ™ºèƒ½åˆ¤æ–­ scope
function detectScope(text: string): 'global' | 'local' {
  const globalIndicators = /å…¨å±€|global|æ‰€æœ‰é¡¹ç›®|all projects|everywhere|ä»»ä½•åœ°æ–¹|é€šç”¨|universal|æ€»æ˜¯|always/i;
  const localIndicators = /è¿™ä¸ªé¡¹ç›®|this project|è¿™é‡Œ|here|å½“å‰|current|æœ¬é¡¹ç›®|è¿™ä¸ªä»“åº“/i;
  
  if (globalIndicators.test(text)) return 'global';
  if (localIndicators.test(text)) return 'local';
  
  // é»˜è®¤ï¼šç¼–ç¨‹é£æ ¼/åå¥½ç±»çš„è§„åˆ™é€šå¸¸æ˜¯ global
  const stylePatterns = /ä»£ç |code|å‘½å|naming|æ ¼å¼|format|é£æ ¼|style|ç¼©è¿›|indent|æ³¨é‡Š|comment/i;
  if (stylePatterns.test(text)) return 'global';
  
  return 'local';
}

// æ™ºèƒ½åˆ¤æ–­é‡è¦æ€§
function detectImportance(text: string, type: 'fact' | 'event' | 'rule'): number {
  let base = type === 'rule' ? 7 : type === 'event' ? 4 : 3;
  
  // å¼ºè°ƒè¯åŠ åˆ†
  const emphasisPatterns = [
    { pattern: /éå¸¸é‡è¦|very important|critical|å…³é”®|crucial|å¿…é¡»|must|ç»å¯¹/i, boost: 2 },
    { pattern: /é‡è¦|important|æ³¨æ„|note|è®°ä½|remember/i, boost: 1 },
    { pattern: /æ°¸è¿œ|always|never|ç»ä¸|ä¸¥ç¦|forbidden/i, boost: 2 },
    { pattern: /å°å¿ƒ|careful|è­¦å‘Š|warning|å±é™©|danger/i, boost: 1 },
  ];
  
  for (const { pattern, boost } of emphasisPatterns) {
    if (pattern.test(text)) {
      base += boost;
    }
  }
  
  // è¸©å‘ç»éªŒåŠ åˆ†ï¼ˆç»éªŒæ•™è®­å¾ˆå®è´µï¼‰
  if (/è¸©å‘|å‘|bug|èŠ±äº†.*æ—¶é—´|æŠ˜è…¾|ç»ˆäº|finally|after.*hours/i.test(text)) {
    base += 2;
  }
  
  return Math.min(base, 10);
}

// æ™ºèƒ½æå–æ ‡ç­¾
function extractTags(text: string): string[] {
  const tags: string[] = [];
  
  // æŠ€æœ¯æ ˆæ ‡ç­¾
  const techPatterns: Record<string, RegExp> = {
    'react': /react/i,
    'vue': /vue/i,
    'angular': /angular/i,
    'node': /node\.?js|nodejs/i,
    'python': /python|py|pip/i,
    'typescript': /typescript|ts/i,
    'javascript': /javascript|js/i,
    'docker': /docker/i,
    'kubernetes': /k8s|kubernetes/i,
    'git': /git|github|gitlab/i,
    'database': /mysql|postgres|mongo|redis|sqlite|æ•°æ®åº“/i,
    'api': /api|rest|graphql|æ¥å£/i,
    'css': /css|sass|scss|tailwind|æ ·å¼/i,
    'testing': /test|jest|mocha|pytest|æµ‹è¯•/i,
    'deploy': /deploy|éƒ¨ç½²|å‘å¸ƒ|ci\/cd/i,
  };
  
  for (const [tag, pattern] of Object.entries(techPatterns)) {
    if (pattern.test(text)) {
      tags.push(tag);
    }
  }
  
  return tags.slice(0, 5); // æœ€å¤š 5 ä¸ªæ ‡ç­¾
}

// æ™ºèƒ½å†…å®¹æå–å’Œæ¸…ç†
function extractContent(userMsg: string, assistantMsg: string, type: 'fact' | 'event' | 'rule'): string {
  let content = userMsg;
  
  // ç§»é™¤å¸¸è§çš„æ— æ„ä¹‰å‰ç¼€
  content = content.replace(/^(å¥½çš„|ok|å—¯|å“¦|é‚£|æ‰€ä»¥|ç„¶å|æ¥ä¸‹æ¥|è¯·|å¸®æˆ‘|éº»çƒ¦)[ï¼Œ,ã€‚.ï¼š:\s]*/i, '');
  content = content.replace(/^(hey|hi|hello|so|well|okay|alright)[,.\s]*/i, '');
  
  // æ ¹æ®ç±»å‹è°ƒæ•´é•¿åº¦
  const maxLength = type === 'rule' ? 300 : type === 'event' ? 200 : 250;
  
  if (content.length > maxLength) {
    // å°è¯•åœ¨å¥å·å¤„æˆªæ–­
    const truncated = content.substring(0, maxLength);
    const lastPeriod = Math.max(
      truncated.lastIndexOf('ã€‚'),
      truncated.lastIndexOf('.'),
      truncated.lastIndexOf('ï¼'),
      truncated.lastIndexOf('!'),
    );
    if (lastPeriod > maxLength * 0.5) {
      content = truncated.substring(0, lastPeriod + 1);
    } else {
      content = truncated + '...';
    }
  }
  
  return content.replace(/\n+/g, ' ').trim();
}

// æ£€æµ‹æ˜¯å¦åŒ…å«æ•æ„Ÿä¿¡æ¯
function containsSensitiveInfo(text: string): boolean {
  const sensitivePatterns = [
    /password\s*[:=]/i,
    /å¯†ç \s*[:=ï¼š]/i,
    /api.?key\s*[:=]/i,
    /secret\s*[:=]/i,
    /token\s*[:=]/i,
    /credential/i,
    /private.?key/i,
    /-----BEGIN/i,  // PEM æ ¼å¼
    /ghp_[a-zA-Z0-9]+/i,  // GitHub token
    /sk-[a-zA-Z0-9]+/i,   // OpenAI key
  ];
  
  return sensitivePatterns.some(p => p.test(text));
}

function analyzeForAutoEncode(userMessage: string, assistantMessage: string): AutoEncodeResult[] {
  const results: AutoEncodeResult[] = [];
  
  // å¤ªçŸ­çš„æ¶ˆæ¯ä¸åˆ†æ
  if (userMessage.length < CONFIG.autoEncode.minMessageLength) {
    return results;
  }
  
  // åŒ…å«æ•æ„Ÿä¿¡æ¯æ—¶ä¸è‡ªåŠ¨ä¿å­˜
  if (containsSensitiveInfo(userMessage) || containsSensitiveInfo(assistantMessage)) {
    return results;
  }
  
  const combined = `${userMessage} ${assistantMessage}`;
  let hasMatch = false;
  
  // 0. æ£€æŸ¥ä¿®æ­£æ¨¡å¼ (ä¼˜å…ˆçº§æœ€é«˜)
  const correctionMatch = matchesAnyPattern(userMessage, CONFIG.autoEncode.correctionPatterns);
  if (correctionMatch.matched) {
    results.push({
      shouldSave: true,
      type: 'fact',
      importance: 9, // ä¿®æ­£é€šå¸¸å¾ˆé‡è¦
      scope: 'local',
      content: extractContent(userMessage, assistantMessage, 'fact'),
      reason: 'User corrected information',
      tags: ['correction', 'fact', ...extractTags(combined)]
    });
    hasMatch = true;
  }

  // 1. æ£€æŸ¥èº«ä»½/ä¸ªäººä¿¡æ¯æ¨¡å¼ï¼ˆä¼˜å…ˆçº§æœ€é«˜ï¼Œè®¾ä¸º globalï¼‰
  const identityMatch = matchesAnyPattern(userMessage, CONFIG.autoEncode.identityPatterns);
  if (identityMatch.matched) {
    results.push({
      shouldSave: true,
      type: 'fact',
      importance: 8,
      scope: 'global',
      content: extractContent(userMessage, assistantMessage, 'fact'),
      reason: 'Personal identity information',
      tags: ['identity', 'personal']
    });
    hasMatch = true;
  }
  
  // 1.5. æ£€æŸ¥è®¡åˆ’/ç›®æ ‡æ¨¡å¼
  if (!hasMatch) {
    const goalMatch = matchesAnyPattern(userMessage, CONFIG.autoEncode.goalPatterns);
    if (goalMatch.matched) {
      results.push({
        shouldSave: true,
        type: 'event',
        importance: 6,
        scope: 'local',
        content: extractContent(userMessage, assistantMessage, 'event'),
        reason: 'User plan/goal detected',
        tags: ['plan', 'goal', ...extractTags(combined)]
      });
      hasMatch = true;
    }
  }
  
  // 1.6. æ£€æŸ¥å®šä¹‰æ¨¡å¼
  if (!hasMatch) {
    const defMatch = matchesAnyPattern(combined, CONFIG.autoEncode.definitionPatterns);
    if (defMatch.matched) {
      results.push({
        shouldSave: true,
        type: 'fact',
        importance: 6,
        scope: 'local',
        content: extractContent(userMessage, assistantMessage, 'fact'),
        reason: 'Concept definition detected',
        tags: ['definition', 'knowledge', ...extractTags(combined)]
      });
      hasMatch = true;
    }
  }

  // 2. æ£€æŸ¥è§„åˆ™æ¨¡å¼
  if (!hasMatch) {
    const ruleMatch = matchesAnyPattern(userMessage, CONFIG.autoEncode.rulePatterns);
    if (ruleMatch.matched) {
      const scope = detectScope(userMessage);
      const importance = detectImportance(userMessage, 'rule');
      results.push({
        shouldSave: true,
        type: 'rule',
        importance,
        scope,
        content: extractContent(userMessage, assistantMessage, 'rule'),
        reason: 'User expressed preference/rule',
        tags: extractTags(combined)
      });
      hasMatch = true;
    }
  }
  
  // 3. æ£€æŸ¥é¡¹ç›®ä¿¡æ¯æ¨¡å¼
  if (!hasMatch) {
    const projectMatch = matchesAnyPattern(userMessage, CONFIG.autoEncode.projectPatterns);
    if (projectMatch.matched) {
      results.push({
        shouldSave: true,
        type: 'fact',
        importance: 5,
        scope: 'local',
        content: extractContent(userMessage, assistantMessage, 'fact'),
        reason: 'Project-specific information',
        tags: ['project', ...extractTags(combined)]
      });
      hasMatch = true;
    }
  }
  
  // 4. æ£€æŸ¥äº‹ä»¶æ¨¡å¼
  if (!hasMatch) {
    const eventMatch = matchesAnyPattern(combined, CONFIG.autoEncode.eventPatterns);
    if (eventMatch.matched) {
      const importance = detectImportance(combined, 'event');
      results.push({
        shouldSave: true,
        type: 'event',
        importance,
        scope: 'local',
        content: extractContent(userMessage, assistantMessage, 'event'),
        reason: 'Significant event detected',
        tags: extractTags(combined)
      });
      hasMatch = true;
    }
  }
  
  // 5. æ£€æŸ¥äº‹å®æ¨¡å¼ï¼ˆæœ€åæ£€æŸ¥ï¼Œé¿å…è¯¯è§¦å‘ï¼‰
  if (!hasMatch) {
    const factMatch = matchesAnyPattern(combined, CONFIG.autoEncode.factPatterns);
    if (factMatch.matched) {
      results.push({
        shouldSave: true,
        type: 'fact',
        importance: detectImportance(combined, 'fact'),
        scope: 'local',
        content: extractContent(userMessage, assistantMessage, 'fact'),
        reason: 'Technical/config information detected',
        tags: extractTags(combined)
      });
    }
  }
  
  return results;
}

// === æ ¸å¿ƒï¼šè®°å¿†å­˜å‚¨ ===
interface MemoryOptions {
  tags?: string[];
  scope?: "global" | "local";
  projectId?: string;
  parentId?: string;
  changeReason?: string;
  source?: string;
  type?: "fact" | "event" | "rule";
  importance?: number;
}

async function saveMemory(content: string, options: MemoryOptions = {}): Promise<string> {
  const database = await initDB();
  const id = `mem_${Date.now()}_${Math.random().toString(36).substring(2, 9)}`;
  const now = Date.now();
  
  const scope = options.scope || "local";
  const projectId = scope === "local" ? (options.projectId || "unknown") : null;
  const tagsStr = options.tags?.length ? options.tags.map(t => t.toLowerCase()).join(",") : null;
  
  const type = options.type || "fact";
  let importance = options.importance || 1;
  let decayRate = CONFIG.defaultDecayRate;

  if (type === 'rule') {
    importance = Math.max(importance, 5); 
    decayRate = 0.01;
  }
  if (importance >= 8) {
    decayRate = 0.0;
  }

  // æ£€æŸ¥æ˜¯å¦å·²æœ‰é«˜åº¦ç›¸ä¼¼çš„è®°å¿†ï¼ˆå»é‡ï¼‰
  const existing = await searchMemoriesInternal(content, projectId || "", 1, null, true);
  if (existing.length > 0 && existing[0].similarity > 0.85) {
    // éå¸¸ç›¸ä¼¼ï¼Œåªæ›´æ–°è®¿é—®è®¡æ•°è€Œä¸åˆ›å»ºæ–°è®°å¿†
    database.prepare(`
      UPDATE memories SET access_count = access_count + 1, last_accessed_at = ?
      WHERE id = ?
    `).run(now, existing[0].id);
    return existing[0].id;
  }

  if (options.parentId) {
    database.prepare(`
      UPDATE memories 
      SET status = 'archived', updated_at = ?, change_reason = ?
      WHERE id = ?
    `).run(now, options.changeReason || "Evolved", options.parentId);
    
    database.prepare(`
      INSERT OR IGNORE INTO memory_links (source_id, target_id, type, strength, created_at)
      SELECT ?, target_id, type, strength, ? FROM memory_links WHERE source_id = ?
    `).run(id, now, options.parentId);
  }

  const embedding = await getEmbedding(content, 'document');
  const embeddingBuffer = Buffer.from(embedding.buffer);

  database.prepare(`
    INSERT INTO memories (
      id, content, tags, scope, project_id, status, parent_id, source, 
      type, importance, decay_rate,
      created_at, updated_at, last_accessed_at
    ) VALUES (?, ?, ?, ?, ?, 'active', ?, ?, ?, ?, ?, ?, ?, ?)
  `).run(
    id, content, tagsStr, scope, projectId, options.parentId || null, options.source || "user_explicit",
    type, importance, decayRate,
    now, now, now
  );

  database.prepare(`
    INSERT INTO vec_memories (memory_id, embedding) VALUES (?, ?)
  `).run(id, embeddingBuffer);

  // è‡ªåŠ¨è¿æ¥
  if (!options.parentId) {
    try {
      const similar = await searchMemoriesInternal(content, projectId || "", 3, null, true);
      for (const mem of similar) {
        if (mem.id !== id && mem.similarity > 0.7) {
          const strength = Math.min(1.0, mem.similarity * 0.8);
          
          // Link New -> Old
          database.prepare(`
            INSERT OR IGNORE INTO memory_links (source_id, target_id, type, strength, created_at)
            VALUES (?, ?, 'auto_association', ?, ?)
          `).run(id, mem.id, strength, now);

          // Link Old -> New (Bidirectional)
          database.prepare(`
            INSERT OR IGNORE INTO memory_links (source_id, target_id, type, strength, created_at)
            VALUES (?, ?, 'auto_association', ?, ?)
          `).run(mem.id, id, strength, now);
        }
      }
    } catch(e) {}
  }

  return id;
}

// === æ ¸å¿ƒï¼šæ··åˆæ£€ç´¢ + æ¿€æ´»æ‰©æ•£ ===
async function searchMemoriesInternal(
  query: string, 
  currentProjectId: string, 
  limit: number = CONFIG.maxMemories,
  targetProjectId: string | null = null,
  disableSpread: boolean = false
) {
  const database = await initDB();
  const queryEmbedding = await getEmbedding(query, 'query');
  const queryBuffer = Buffer.from(queryEmbedding.buffer);
  const now = Date.now();

  const vecResults = database.prepare(`
    SELECT memory_id, distance
    FROM vec_memories
    WHERE embedding MATCH ? AND k = ?
    ORDER BY distance
  `).all(queryBuffer, limit * 5);

  if (vecResults.length === 0) return [];

  const ids = vecResults.map((r: any) => r.memory_id);
  const placeholders = ids.map(() => "?").join(",");

  const rows = database.prepare(`
    SELECT * FROM memories 
    WHERE id IN (${placeholders})
    AND status = 'active'
  `).all(...ids);

  const effectiveProjectId = targetProjectId || currentProjectId;
  
  const results = await Promise.all(rows.map(async (row: any) => {
    const vec = vecResults.find((v: any) => v.memory_id === row.id);
    const distance = vec ? vec.distance : 1.0;
    const similarity = Math.max(0, 1 - (distance * distance / 2));
    
    const daysElapsed = (now - (row.last_accessed_at || row.created_at)) / (1000 * 60 * 60 * 24);
    const retention = 1 / (1 + (row.decay_rate || 0.05) * daysElapsed);
    
    const importanceBoost = 1 + (row.importance || 1) * 0.1; 
    const accessBoost = 1 + Math.log1p(row.access_count || 0) * 0.1;

    let contextFactor = 1.0;
    const isLocalContext = (row.scope === 'local' && row.project_id === effectiveProjectId);
    const isGlobal = (row.scope === 'global');
    
    if (!isGlobal && !isLocalContext) {
      const activity = await getProjectActivity(row.project_id);
      
      if (activity === 'recent') {
        contextFactor = CONFIG.context.recentProjectFactor;
      } else if (activity === 'stale') {
        contextFactor = CONFIG.context.staleProjectFactor;
      } else {
        if (similarity > 0.85 && (row.importance || 0) >= 7) {
          contextFactor = CONFIG.context.alienBreakthroughFactor;
        } else {
          contextFactor = 0.2;
        }
      }
    }

    const finalScore = similarity * retention * importanceBoost * accessBoost * contextFactor;

    return {
      ...row,
      distance,
      similarity,
      retention,
      contextFactor,
      finalScore,
      isAlien: (!isGlobal && !isLocalContext),
      spreadSource: null as string | null
    };
  }));

  // æ¿€æ´»æ‰©æ•£
  let spreadResults: any[] = [];
  if (!disableSpread && results.length > 0) {
    const topIds = results
      .sort((a, b) => b.finalScore - a.finalScore)
      .slice(0, 2)
      .map(r => r.id);
    
    if (topIds.length > 0) {
      const linkPlaceholders = topIds.map(() => "?").join(",");
      const links = database.prepare(`
        SELECT source_id, target_id, strength FROM memory_links 
        WHERE source_id IN (${linkPlaceholders}) AND strength >= ?
      `).all(...topIds, CONFIG.spreading.minLinkStrength);
      
      const linkedIds = links
        .map((l: any) => l.target_id)
        .filter((id: string) => !ids.includes(id));
      
      if (linkedIds.length > 0) {
        const linkedPlaceholders = linkedIds.map(() => "?").join(",");
        const linkedRows = database.prepare(`
          SELECT * FROM memories 
          WHERE id IN (${linkedPlaceholders}) AND status = 'active'
        `).all(...linkedIds);
        
        for (const row of linkedRows) {
          const link = links.find((l: any) => l.target_id === row.id);
          const sourceResult = results.find(r => r.id === link?.source_id);
          
          if (sourceResult && link) {
            const spreadScore = sourceResult.finalScore * link.strength * CONFIG.spreading.spreadDecay;
            spreadResults.push({
              ...row,
              distance: 999,
              similarity: 0,
              retention: 1,
              contextFactor: 1,
              finalScore: spreadScore,
              isAlien: row.scope === 'local' && row.project_id !== effectiveProjectId,
              spreadSource: link.source_id
            });
          }
        }
      }
    }
  }

  const allResults = [...results, ...spreadResults]
    .filter(r => r.finalScore > 0.25)
    .sort((a, b) => b.finalScore - a.finalScore);
  
  const seen = new Set<string>();
  const uniqueResults = allResults.filter(r => {
    if (seen.has(r.id)) return false;
    seen.add(r.id);
    return true;
  }).slice(0, limit);

  // æ›´æ–°è®¿é—®ç»Ÿè®¡
  const hitIds = uniqueResults.filter(r => !r.spreadSource).map(r => r.id);
  if (hitIds.length > 0) {
    const updatePlaceholders = hitIds.map(() => "?").join(",");
    database.prepare(`
      UPDATE memories 
      SET access_count = access_count + 1, last_accessed_at = ?
      WHERE id IN (${updatePlaceholders})
    `).run(now, ...hitIds);
  }

  return uniqueResults;
}

async function searchMemories(query: string, projectId: string, limit: number = CONFIG.maxMemories) {
  return searchMemoriesInternal(query, projectId, limit, null, false);
}

// === V5.5.0 å¯åŠ¨å”¤é†’ä¸æ™ºèƒ½æ£€ç´¢ ===

// ä¼°ç®— Token æ•°é‡ï¼ˆç®€æ˜“ç‰ˆï¼šä¸­æ–‡çº¦ 0.5 token/å­—ï¼Œè‹±æ–‡çº¦ 0.25 token/å­—ï¼‰
function estimateTokens(text: string): number {
  const chineseChars = (text.match(/[\u4e00-\u9fa5]/g) || []).length;
  const otherChars = text.length - chineseChars;
  return Math.ceil(chineseChars * 0.7 + otherChars * 0.3);
}

// è·å–å¯åŠ¨å”¤é†’è®°å¿†ï¼ˆæ ¸å¿ƒè®°å¿† + æœ€è¿‘ 24hï¼‰
async function getStartupMemories(projectId: string): Promise<any[]> {
  if (!CONFIG.startupRecall.enabled) return [];
  
  const database = await initDB();
  const now = Date.now();
  const lookbackMs = CONFIG.startupRecall.lookbackHours * 60 * 60 * 1000;
  const cutoffTime = now - lookbackMs;
  
  // 1. è·å–æ ¸å¿ƒè®°å¿†ï¼ˆé«˜é‡è¦æ€§ï¼Œä¸é™é¡¹ç›®ï¼‰
  const coreMemories = database.prepare(`
    SELECT *, 'core' as recall_type FROM memories 
    WHERE status = 'active' 
    AND importance >= ?
    ORDER BY importance DESC, access_count DESC
    LIMIT 20
  `).all(CONFIG.startupRecall.minImportance);
  
  // 2. è·å–æœ€è¿‘ 24h çš„è®°å¿†ï¼ˆåŒ…æ‹¬æ‰€æœ‰é¡¹ç›®ï¼Œå› ä¸ºç”¨æˆ·å¯èƒ½åœ¨ä¸åŒç›®å½•å·¥ä½œï¼‰
  const recentMemories = database.prepare(`
    SELECT *, 'recent' as recall_type FROM memories 
    WHERE status = 'active' 
    AND created_at >= ?
    ORDER BY created_at DESC
    LIMIT 50
  `).all(cutoffTime);
  
  // 3. åˆå¹¶å»é‡
  const seen = new Set<string>();
  const combined: any[] = [];
  
  // æ ¸å¿ƒè®°å¿†ä¼˜å…ˆ
  for (const mem of coreMemories) {
    if (!seen.has(mem.id)) {
      seen.add(mem.id);
      combined.push(mem);
    }
  }
  
  // ç„¶åæ˜¯è¿‘æœŸè®°å¿†
  for (const mem of recentMemories) {
    if (!seen.has(mem.id)) {
      seen.add(mem.id);
      combined.push(mem);
    }
  }
  
  // 4. åº”ç”¨ç¡¬é™åˆ¶
  return combined.slice(0, CONFIG.startupRecall.maxMemories);
}

// ç”¨æœ¬åœ° LLM å‹ç¼©å¯åŠ¨è®°å¿†ä¸ºæ‘˜è¦
async function summarizeStartupMemoriesWithLLM(memories: any[]): Promise<string | null> {
  if (!CONFIG.localLLM.enabled || !CONFIG.startupRecall.useLLMSummary) return null;
  
  const isAvailable = await checkOllamaAvailable();
  if (!isAvailable) return null;
  
  try {
    // æ ¼å¼åŒ–è®°å¿†åˆ—è¡¨
    const memoryList = memories.map((m, i) => {
      const typeIcon = m.type === 'rule' ? 'ğŸ“œ' : (m.type === 'event' ? 'ğŸ“…' : 'ğŸ’¡');
      const recallType = m.recall_type === 'core' ? '[æ ¸å¿ƒ]' : '[è¿‘æœŸ]';
      return `${i + 1}. ${typeIcon} ${recallType} ${m.content}`;
    }).join('\n');
    
    const prompt = `ä½ æ˜¯ä¸€ä¸ªè®°å¿†æ•´ç†åŠ©æ‰‹ã€‚è¯·å°†ä»¥ä¸‹è®°å¿†å‹ç¼©æˆä¸€æ®µç®€æ´çš„"æ™¨æŠ¥æ‘˜è¦"ï¼Œä¿ç•™æœ€é‡è¦çš„ä¿¡æ¯ã€‚

## åŸå§‹è®°å¿†åˆ—è¡¨
${memoryList}

## è¦æ±‚
1. ç”¨ç®€æ´çš„è¯­è¨€æ¦‚æ‹¬æ ¸å¿ƒä¿¡æ¯
2. ä¿ç•™ç”¨æˆ·çš„åå¥½è§„åˆ™å’Œé‡è¦äº‹ä»¶
3. è¾“å‡ºé•¿åº¦æ§åˆ¶åœ¨ 300 å­—ä»¥å†…
4. ä½¿ç”¨ç”¨æˆ·çš„è¯­è¨€ï¼ˆä¸­æ–‡/è‹±æ–‡ï¼‰

## è¾“å‡ºæ ¼å¼
ç›´æ¥è¾“å‡ºæ‘˜è¦æ–‡æœ¬ï¼Œä¸è¦åŠ ä»»ä½•å‰ç¼€æˆ–è§£é‡Šã€‚`;

    const controller = new AbortController();
    const timeoutId = setTimeout(() => controller.abort(), CONFIG.localLLM.timeout * 2); // ç»™å‹ç¼©ä»»åŠ¡æ›´å¤šæ—¶é—´
    
    const response = await fetch(`${CONFIG.localLLM.baseUrl}/api/generate`, {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({
        model: CONFIG.localLLM.model,
        prompt: prompt,
        stream: false,
        options: {
          temperature: 0,
          num_predict: CONFIG.startupRecall.summaryMaxTokens,
        }
      }),
      signal: controller.signal
    });
    
    clearTimeout(timeoutId);
    
    if (!response.ok) return null;
    
    const data = await response.json();
    const summary = data.response?.trim();
    
    return summary || null;
  } catch (e) {
    return null;
  }
}

// V5.7.0 åå°ä»£è°¢ï¼šç”¨ LLM æ€»ç»“è®°å¿†ç°‡
async function summarizeClusterWithLLM(memories: any[]): Promise<string | null> {
  if (!CONFIG.localLLM.enabled) return null;
  const isAvailable = await checkOllamaAvailable();
  if (!isAvailable) return null;

  try {
    const memoryList = memories.map(m => `- ${m.content}`).join('\n');
    const prompt = `ä½ æ˜¯ä¸€ä¸ªè®°å¿†æ•´ç†ä¸“å®¶ã€‚è¯·å°†ä»¥ä¸‹ç›¸å…³çš„ç¢ç‰‡è®°å¿†æ•´åˆæˆä¸€æ¡å®Œæ•´çš„ã€é«˜è´¨é‡çš„è®°å¿†ã€‚

## è®°å¿†ç¢ç‰‡
${memoryList}

## è¦æ±‚
1. æå–æ ¸å¿ƒäº‹å®ã€è§„åˆ™æˆ–äº‹ä»¶
2. å»é™¤é‡å¤å’Œçç¢ç»†èŠ‚
3. ç”Ÿæˆä¸€æ¡ç²¾ç‚¼çš„æ€»ç»“ï¼ˆå»ºè®® 50-100 å­—ï¼‰
4. å¦‚æœåŒ…å«å†²çªä¿¡æ¯ï¼Œä»¥æœ€æ–°çš„ä¸ºå‡†

## è¾“å‡º
ç›´æ¥è¾“å‡ºæ•´ç†åçš„å†…å®¹ï¼Œä¸è¦è§£é‡Šã€‚`;

    const controller = new AbortController();
    const timeoutId = setTimeout(() => controller.abort(), CONFIG.localLLM.timeout);
    
    const response = await fetch(`${CONFIG.localLLM.baseUrl}/api/generate`, {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({
        model: CONFIG.localLLM.model,
        prompt: prompt,
        stream: false,
        options: { temperature: 0, num_predict: 200 }
      }),
      signal: controller.signal
    });
    
    clearTimeout(timeoutId);
    if (!response.ok) return null;
    
    const data = await response.json();
    return data.response?.trim() || null;
  } catch (e) {
    return null;
  }
}

// V5.5.0 ç”¨æœ¬åœ° LLM å¢å¼ºæŸ¥è¯¢ï¼ˆç†è§£çŸ­æ¶ˆæ¯çš„çœŸå®æ„å›¾ï¼‰
async function enhanceQueryWithLLM(
  userMessage: string,
  recentHistory: Array<{role: string, content: string}>
): Promise<string | null> {
  if (!CONFIG.localLLM.enabled || !CONFIG.ragSearch.queryEnhancement) return null;
  
  const isAvailable = await checkOllamaAvailable();
  if (!isAvailable) return null;
  
  try {
    // æ ¼å¼åŒ–æœ€è¿‘çš„å¯¹è¯å†å²
    const historyText = recentHistory.slice(-6).map(msg => {
      const role = msg.role === 'user' ? 'ç”¨æˆ·' : 'åŠ©æ‰‹';
      // æˆªæ–­å¤ªé•¿çš„æ¶ˆæ¯
      const content = msg.content.length > 200 ? msg.content.substring(0, 200) + '...' : msg.content;
      return `${role}: ${content}`;
    }).join('\n');
    
    const prompt = `åˆ†æç”¨æˆ·çš„æœ€æ–°æ¶ˆæ¯ï¼Œç»“åˆå¯¹è¯ä¸Šä¸‹æ–‡ï¼Œæå–æ£€ç´¢å…³é”®è¯ã€‚

## å¯¹è¯å†å²
${historyText}

## ç”¨æˆ·æœ€æ–°æ¶ˆæ¯
${userMessage}

## ä»»åŠ¡
1. ç†è§£ç”¨æˆ·çœŸæ­£æƒ³é—®/è¯´çš„æ˜¯ä»€ä¹ˆ
2. æå– 3-5 ä¸ªç”¨äºæ£€ç´¢è®°å¿†åº“çš„å…³é”®è¯
3. å…³é”®è¯åº”è¯¥è¦†ç›–ä¸»é¢˜ã€æŠ€æœ¯æ ˆã€æ“ä½œç±»å‹ç­‰

## è¾“å‡ºæ ¼å¼ï¼ˆç›´æ¥è¾“å‡ºï¼Œä¸è¦è§£é‡Šï¼‰
å…³é”®è¯1 å…³é”®è¯2 å…³é”®è¯3`;

    const controller = new AbortController();
    const timeoutId = setTimeout(() => controller.abort(), 3000); // 3ç§’è¶…æ—¶ï¼Œä¿æŒå¿«é€Ÿ
    
    const response = await fetch(`${CONFIG.localLLM.baseUrl}/api/generate`, {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({
        model: CONFIG.localLLM.model,
        prompt: prompt,
        stream: false,
        options: {
          temperature: 0,
          num_predict: 50, // åªéœ€è¦å‡ ä¸ªå…³é”®è¯
        }
      }),
      signal: controller.signal
    });
    
    clearTimeout(timeoutId);
    
    if (!response.ok) return null;
    
    const data = await response.json();
    const keywords = data.response?.trim();
    
    if (keywords && keywords.length > 0 && keywords.length < 200) {
      console.log(`[Hippocampus] Query enhanced: "${userMessage}" -> "${keywords}"`);
      return keywords;
    }
    
    return null;
  } catch (e) {
    // è¶…æ—¶æˆ–å…¶ä»–é”™è¯¯ï¼Œé™é»˜è¿”å› null
    return null;
  }
}

// ç”¨æœ¬åœ° LLM å¯¹æœç´¢ç»“æœè¿›è¡Œé‡æ’åº
async function rerankMemoriesWithLLM(
  query: string, 
  memories: any[], 
  outputLimit: number = CONFIG.ragSearch.rerankOutputLimit
): Promise<any[] | null> {
  if (!CONFIG.localLLM.enabled || !CONFIG.ragSearch.rerankWithLLM) return null;
  
  const isAvailable = await checkOllamaAvailable();
  if (!isAvailable) return null;
  
  try {
    // æ ¼å¼åŒ–è®°å¿†åˆ—è¡¨ï¼ˆå¸¦ç¼–å·ï¼‰
    const memoryList = memories.slice(0, 50).map((m, i) => {
      return `[${i}] ${m.content}`;
    }).join('\n');
    
    const prompt = `ä½ æ˜¯ä¸€ä¸ªè®°å¿†æ£€ç´¢åŠ©æ‰‹ã€‚æ ¹æ®ç”¨æˆ·çš„é—®é¢˜ï¼Œä»ä»¥ä¸‹è®°å¿†åˆ—è¡¨ä¸­é€‰å‡ºæœ€ç›¸å…³çš„ ${outputLimit} æ¡ã€‚

## ç”¨æˆ·é—®é¢˜
${query}

## è®°å¿†åˆ—è¡¨
${memoryList}

## è¦æ±‚
1. é€‰æ‹©ä¸é—®é¢˜æœ€ç›¸å…³çš„è®°å¿†
2. æŒ‰ç›¸å…³åº¦ä»é«˜åˆ°ä½æ’åº
3. åªè¾“å‡ºç¼–å·ï¼Œç”¨é€—å·åˆ†éš”
4. ä¾‹å¦‚ï¼š0,3,7,2,5

## è¾“å‡º
ç›´æ¥è¾“å‡ºç¼–å·åˆ—è¡¨ï¼š`;

    const controller = new AbortController();
    const timeoutId = setTimeout(() => controller.abort(), CONFIG.localLLM.timeout);
    
    const response = await fetch(`${CONFIG.localLLM.baseUrl}/api/generate`, {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({
        model: CONFIG.localLLM.model,
        prompt: prompt,
        stream: false,
        options: {
          temperature: 0,
          num_predict: 100,
        }
      }),
      signal: controller.signal
    });
    
    clearTimeout(timeoutId);
    
    if (!response.ok) return null;
    
    const data = await response.json();
    const text = data.response?.trim() || '';
    
    // è§£æç¼–å·åˆ—è¡¨
    const indices = text.match(/\d+/g)?.map(Number) || [];
    const validIndices = indices.filter(i => i >= 0 && i < memories.length);
    
    if (validIndices.length === 0) return null;
    
    // æŒ‰ LLM æ’åºè¿”å›è®°å¿†
    const reranked = validIndices.slice(0, outputLimit).map(i => memories[i]);
    return reranked;
  } catch (e) {
    return null;
  }
}

// æ ¼å¼åŒ–è®°å¿†ä¸ºæ³¨å…¥æ–‡æœ¬ï¼ˆå¸¦ Token é™åˆ¶ï¼‰
function formatMemoriesForInjection(
  memories: any[], 
  maxTokens: number = CONFIG.startupRecall.maxTokens
): string {
  if (memories.length === 0) return '';
  
  let totalTokens = 0;
  const lines: string[] = [];
  
  for (const m of memories) {
    const typeMark = m.type === 'rule' ? 'RULE' : 'INFO';
    const impMark = (m.importance || 0) > 5 ? 'â˜…' : '';
    const coreMark = m.recall_type === 'core' ? ' [CORE]' : '';
    const line = `- [${typeMark}${impMark}] ${m.content}${coreMark} (ID:${m.id})`;
    
    const lineTokens = estimateTokens(line);
    if (totalTokens + lineTokens > maxTokens) break;
    
    totalTokens += lineTokens;
    lines.push(line);
  }
  
  return lines.join('\n');
}

// === ç¡çœ æ•´ç† ===
interface ConsolidationResult {
  merged: number;
  promoted: number;
  pruned: number;
  newLinks: number;
}

async function performConsolidation(projectId?: string): Promise<ConsolidationResult> {
  const database = await initDB();
  const now = Date.now();
  const result: ConsolidationResult = { merged: 0, promoted: 0, pruned: 0, newLinks: 0 };
  
  const maxAge = now - CONFIG.consolidation.fragmentMaxAgeDays * 24 * 60 * 60 * 1000;
  
  let fragmentQuery = `
    SELECT id, content, project_id, type, importance, access_count, created_at
    FROM memories 
    WHERE status = 'active' 
    AND type IN ('event', 'fact') 
    AND importance < 5
    AND created_at > ?
  `;
  const queryParams: any[] = [maxAge];
  
  if (projectId) {
    fragmentQuery += ` AND project_id = ?`;
    queryParams.push(projectId);
  }
  fragmentQuery += ` ORDER BY created_at DESC LIMIT 50`;
  
  const fragments = database.prepare(fragmentQuery).all(...queryParams);
  
  if (fragments.length < CONFIG.consolidation.minFragmentsForMerge) {
    return result;
  }
  
  const embeddings: Map<string, Float32Array> = new Map();
  for (const frag of fragments) {
    const embedding = await getEmbedding(frag.content, 'document');
    embeddings.set(frag.id, embedding);
  }
  
  const clusters: any[][] = [];
  const used = new Set<string>();
  
  for (const frag of fragments) {
    if (used.has(frag.id)) continue;
    
    const cluster = [frag];
    used.add(frag.id);
    const fragEmb = embeddings.get(frag.id)!;
    
    for (const other of fragments) {
      if (used.has(other.id)) continue;
      if (frag.project_id !== other.project_id) continue;
      
      const otherEmb = embeddings.get(other.id)!;
      const similarity = cosineSimilarity(fragEmb, otherEmb);
      
      if (similarity > CONFIG.consolidation.similarityThreshold) {
        cluster.push(other);
        used.add(other.id);
      }
    }
    
    if (cluster.length >= CONFIG.consolidation.minFragmentsForMerge) {
      clusters.push(cluster);
    }
  }
  
  for (const cluster of clusters) {
    const contents = cluster.map(c => c.content);
    let mergedContent: string;
    
    // V5.7.0: å°è¯•ä½¿ç”¨ LLM è¿›è¡Œæ™ºèƒ½èåˆ (Metabolism)
    const llmSummary = await summarizeClusterWithLLM(cluster);
    
    if (llmSummary) {
      mergedContent = `[LLM Consolidated] ${llmSummary}`;
    } else {
      // Fallback: ç®€å•çš„æ–‡æœ¬æ‹¼æ¥
      if (contents.length <= 3) {
        mergedContent = `[Consolidated] ${contents.join(' | ')}`;
      } else {
        mergedContent = `[Consolidated from ${contents.length} items] ${contents.sort((a, b) => b.length - a.length)[0]}`;
      }
    }
    
    const avgImportance = Math.ceil(cluster.reduce((sum, c) => sum + (c.importance || 1), 0) / cluster.length) + 1;
    
    const newId = await saveMemory(mergedContent, {
      type: 'fact',
      importance: Math.min(avgImportance, 7),
      scope: 'local',
      projectId: cluster[0].project_id,
      source: 'consolidation_v5.7'
    });
    
    const fragIds = cluster.map(c => c.id);
    const archivePlaceholders = fragIds.map(() => "?").join(",");
    database.prepare(`
      UPDATE memories SET status = 'archived', change_reason = 'Consolidated into ${newId}'
      WHERE id IN (${archivePlaceholders})
    `).run(...fragIds);
    
    for (const fragId of fragIds) {
      database.prepare(`
        INSERT OR IGNORE INTO memory_links (source_id, target_id, type, strength, created_at)
        VALUES (?, ?, 'consolidation', 0.8, ?)
      `).run(newId, fragId, now);
      result.newLinks++;
    }
    
    result.merged += cluster.length;
  }
  
  const promoted = database.prepare(`
    UPDATE memories 
    SET importance = MIN(importance + 2, 10), updated_at = ?
    WHERE status = 'active' 
    AND type = 'event' 
    AND access_count >= ?
    AND importance < 8
  `).run(now, CONFIG.consolidation.autoPromoteAccessCount);
  result.promoted = promoted.changes;
  
  return result;
}

function cosineSimilarity(a: Float32Array, b: Float32Array): number {
  let dot = 0, normA = 0, normB = 0;
  for (let i = 0; i < a.length; i++) {
    dot += a[i] * b[i];
    normA += a[i] * a[i];
    normB += b[i] * b[i];
  }
  return dot / (Math.sqrt(normA) * Math.sqrt(normB));
}

async function consolidateMemories(projectId: string) {
  const database = await initDB();
  const rows = database.prepare(`
    SELECT id, content, type, importance, access_count, created_at FROM memories
    WHERE project_id = ? AND scope = 'local' AND status = 'active'
    AND type IN ('event', 'fact') AND importance < 5
    ORDER BY created_at DESC LIMIT 20
  `).all(projectId);
  
  return rows;
}

// === æ’ä»¶å¯¼å‡º ===
export default function (pi: any) {
  
  // å½“å‰ä¼šè¯çš„å¯¹è¯ç¼“å­˜ï¼ˆå†…å­˜ä¸­ï¼‰
  let sessionBuffer: Array<{role: string, content: string}> = [];
  let currentProjectId: string = "";
  
  // V5.5.0 å¯åŠ¨å”¤é†’ç¼“å­˜
  let startupRecallContent: string = "";
  let startupRecallReady: boolean = false;  // æ ‡è®°å¯åŠ¨å”¤é†’æ˜¯å¦å®Œæˆ
  
  // Tool 1: Save Memory
  pi.registerTool({
    name: "save_memory",
    description: "å­˜å…¥é•¿æœŸè®°å¿†ã€‚åƒäººè„‘ä¸€æ ·ï¼Œæ”¯æŒåŒºåˆ†äº‹å®/è§„åˆ™/ç»å†ï¼Œå¹¶æ ‡è®°é‡è¦æ€§ã€‚",
    parameters: Type.Object({
      content: Type.String({ description: "è®°å¿†å†…å®¹" }),
      type: Type.Optional(Type.String({ description: "'fact'(äº‹å®), 'rule'(è§„åˆ™/åå¥½), 'event'(ç»å†/äº‹ä»¶)ã€‚é»˜è®¤ä¸º fact" })),
      importance: Type.Optional(Type.Number({ description: "é‡è¦æ€§ 1-10ã€‚1=çäº‹, 10=æ ¸å¿ƒåŸåˆ™ã€‚é»˜è®¤ä¸º 1" })),
      tags: Type.Array(Type.String(), { default: [] }),
      scope: Type.Optional(Type.String({ description: "'global' æˆ– 'local'" })),
      previous_memory_id: Type.Optional(Type.String({ description: "å¦‚æœæ˜¯ä¿®æ­£æ—§è®°å¿†ï¼Œä¼ å…¥æ—§ID" })),
      change_reason: Type.Optional(Type.String())
    }),
    async execute(id: string, params: any, signal: any, onUpdate: any, ctx: any) {
      try {
        const projectId = getProjectHash(ctx.cwd);
        const memId = await saveMemory(params.content, {
          tags: params.tags,
          scope: params.scope || "local",
          projectId: projectId,
          parentId: params.previous_memory_id,
          changeReason: params.change_reason,
          type: params.type as any,
          importance: params.importance
        });
        
        return { 
          content: [{ type: "text", text: `âœ“ Memory solidified (ID: ${memId})\nType: ${params.type||'fact'} | Importance: ${params.importance||1}` }], 
          details: { id: memId } 
        };
      } catch (error: any) {
        return { content: [{ type: "text", text: `Error: ${error.message}` }], isError: true };
      }
    }
  });

  // Tool 2: Search Memory
  pi.registerTool({
    name: "search_memory",
    description: "å›å¿†ã€‚åŸºäºè¯­ä¹‰ç›¸ä¼¼åº¦ã€æ—¶é—´è¡°å‡ã€é‡è¦æ€§å’Œè®¿é—®é¢‘ç‡è¿›è¡Œæ··åˆæ£€ç´¢ï¼Œæ”¯æŒæ¿€æ´»æ‰©æ•£ã€‚",
    parameters: Type.Object({
      query: Type.String(),
      limit: Type.Optional(Type.Number()),
      project: Type.Optional(Type.String({ description: "æŒ‡å®šé¡¹ç›®åç§°è¿›è¡Œè·¨é¡¹ç›®æœç´¢" }))
    }),
    async execute(id: string, params: any, signal: any, onUpdate: any, ctx: any) {
      const currentProjectId = getProjectHash(ctx.cwd);
      
      let targetProjectId: string | null = null;
      if (params.project) {
        const found = await findProjectByName(params.project);
        if (found) {
          targetProjectId = found.id;
        } else {
          return { content: [{ type: "text", text: `âš ï¸ Project '${params.project}' not found. Please check the name using 'list_projects'.` }] };
        }
      }
      
      const results = await searchMemoriesInternal(
        params.query, 
        currentProjectId, 
        params.limit || CONFIG.maxMemories,
        targetProjectId,
        false
      );
      
      // æ›´æ–°çŠ¶æ€æ 
      if (results.length > 0 && ctx.ui) {
        lastRecallCount = results.length;
        updateStatusBar(ctx);
      }
      
      if (results.length === 0) return { content: [{ type: "text", text: "No relevant memories found." }] };

      const allMemories = results.map((r: any) => {
        let icon = r.scope === 'global' ? 'ğŸŒ' : 'ğŸ ';
        if (r.isAlien) icon = 'ğŸ›¸';
        if (r.spreadSource) icon = 'ğŸ”—';
        const typeIcon = r.type === 'rule' ? 'ğŸ“œ' : (r.type === 'event' ? 'ğŸ“…' : 'ğŸ’¡');
        const score = Math.round(r.finalScore * 100);
        return `[${r.id}] ${icon}${typeIcon} (Act:${score}%) ${r.content}`;
      }).join("\n");

      const summary = `ğŸ§  Recalled ${results.length} memories`;

      return { 
        content: [{ type: "text", text: `${summary}\n${allMemories}` }], 
        details: { results, summary, count: results.length } 
      };
    },
    renderResult(result: any, options: any, theme: any) {
      const count = result.details?.count || 0;
      const summary = result.details?.summary || `ğŸ§  Recalled ${count} memories`;
      return new Text(theme.fg("accent", summary), 0, 0);
    }
  });

  // Tool 3: Connect Memories
  pi.registerTool({
    name: "connect_memories",
    description: "æ‰‹åŠ¨å»ºç«‹ä¸¤æ¡è®°å¿†ä¹‹é—´çš„å…³è”ï¼ˆçªè§¦è¿æ¥ï¼‰ã€‚",
    parameters: Type.Object({
      source_id: Type.String(),
      target_id: Type.String(),
      relationship: Type.String({ description: "å…³è”æè¿°ï¼Œå¦‚ 'causes', 'contradicts', 'relates_to'" }),
      strength: Type.Optional(Type.Number({ description: "0.1 - 1.0" }))
    }),
    async execute(id: string, params: any, signal: any, onUpdate: any, ctx: any) {
      const db = await initDB();
      db.prepare(`
        INSERT OR REPLACE INTO memory_links (source_id, target_id, type, strength, created_at)
        VALUES (?, ?, ?, ?, ?)
      `).run(params.source_id, params.target_id, params.relationship, params.strength || 1.0, Date.now());
      return { content: [{ type: "text", text: `âœ“ Synapse established: ${params.source_id} <--> ${params.target_id}` }] };
    }
  });

  // Tool 4: Consolidate
  pi.registerTool({
    name: "consolidate_memories",
    description: "è§¦å‘åå°è®°å¿†æ•´ç†ï¼ˆä»£è°¢ï¼‰ã€‚è‡ªåŠ¨åˆå¹¶ç›¸ä¼¼çš„ç¢ç‰‡è®°å¿†ï¼Œå¹¶æå‡é«˜é¢‘è®°å¿†çš„é‡è¦æ€§ã€‚è¿™é€šå¸¸åœ¨ä¼šè¯ç»“æŸæ—¶è‡ªåŠ¨æ‰§è¡Œï¼Œä½†ä¹Ÿå¯ä»¥æ‰‹åŠ¨è§¦å‘ã€‚",
    parameters: Type.Object({}),
    async execute(id: string, params: any, signal: any, onUpdate: any, ctx: any) {
      const projectId = getProjectHash(ctx.cwd);
      
      // ç›´æ¥æ‰§è¡Œåå°æ•´ç†ï¼Œè€Œä¸æ˜¯åˆ—å‡ºç¢ç‰‡
      const result = await performConsolidation(projectId);
      
      if (result.merged === 0 && result.promoted === 0) {
        return { content: [{ type: "text", text: "Memory is clean. No consolidation needed right now." }] };
      }
      
      return { 
        content: [{ type: "text", text: `âœ“ Background Consolidation Complete:\n- Merged: ${result.merged} fragments\n- Promoted: ${result.promoted} important memories\n- New Links: ${result.newLinks} synapses created` }] 
      };
    }
  });

  // Tool 5: List Projects
  pi.registerTool({
    name: "list_projects",
    description: "åˆ—å‡ºæ‰€æœ‰å·²çŸ¥çš„é¡¹ç›®åŠå…¶æœ€è¿‘æ´»è·ƒæ—¶é—´ã€‚",
    parameters: Type.Object({}),
    async execute(id: string, params: any, signal: any, onUpdate: any, ctx: any) {
      const database = await initDB();
      const projects = database.prepare(`
        SELECT name, path, last_active_at FROM projects 
        ORDER BY last_active_at DESC LIMIT 20
      `).all();
      
      if (projects.length === 0) {
        return { content: [{ type: "text", text: "No projects registered yet." }] };
      }
      
      const list = projects.map((p: any) => {
        const daysAgo = Math.floor((Date.now() - p.last_active_at) / (1000 * 60 * 60 * 24));
        return `- **${p.name}** (${daysAgo}d ago) â†’ ${p.path}`;
      }).join("\n");
      
      return { content: [{ type: "text", text: `ğŸ“ Known Projects:\n${list}` }] };
    }
  });

  // Tool 6: Memory Status (V5.5.0 Enhanced)
  pi.registerTool({
    name: "memory_status",
    description: "æŸ¥çœ‹è®°å¿†ç³»ç»ŸçŠ¶æ€ï¼šæœ¬åœ° LLM å¯ç”¨æ€§ã€è®°å¿†ç»Ÿè®¡ã€é…ç½®ä¿¡æ¯ã€‚",
    parameters: Type.Object({}),
    async execute(id: string, params: any, signal: any, onUpdate: any, ctx: any) {
      // Force refresh Ollama status
      ollamaAvailable = null;

      const database = await initDB();
      const projectId = getProjectHash(ctx.cwd);
      
      // ç»Ÿè®¡ä¿¡æ¯
      const totalMemories = database.prepare(`SELECT COUNT(*) as count FROM memories WHERE status = 'active'`).get();
      const localMemories = database.prepare(`SELECT COUNT(*) as count FROM memories WHERE status = 'active' AND project_id = ?`).get(projectId);
      const globalMemories = database.prepare(`SELECT COUNT(*) as count FROM memories WHERE status = 'active' AND scope = 'global'`).get();
      const ruleCount = database.prepare(`SELECT COUNT(*) as count FROM memories WHERE status = 'active' AND type = 'rule'`).get();
      const factCount = database.prepare(`SELECT COUNT(*) as count FROM memories WHERE status = 'active' AND type = 'fact'`).get();
      const eventCount = database.prepare(`SELECT COUNT(*) as count FROM memories WHERE status = 'active' AND type = 'event'`).get();
      const linkCount = database.prepare(`SELECT COUNT(*) as count FROM memory_links`).get();
      const autoEncoded = database.prepare(`SELECT COUNT(*) as count FROM memories WHERE source IN ('auto_encode', 'local_llm')`).get();
      
      // æ£€æµ‹æœ¬åœ° LLM
      const ollamaStatus = await checkOllamaAvailable();
      
      let status = `## ğŸ§  Hippocampus V5.6.0 Status\n\n`;
      
      // æœ¬åœ° LLM çŠ¶æ€
      status += `### ğŸ¤– Local LLM Analyzer\n`;
      if (CONFIG.localLLM.enabled) {
        if (ollamaStatus) {
          status += `| Setting | Value |\n|---------|-------|\n`;
          status += `| Status | âœ… **Online** |\n`;
          status += `| Provider | ${CONFIG.localLLM.provider} |\n`;
          status += `| Model | \`${CONFIG.localLLM.model}\` |\n`;
          status += `| Endpoint | ${CONFIG.localLLM.baseUrl} |\n`;
          status += `| Timeout | ${CONFIG.localLLM.timeout}ms |\n`;
          status += `| Temperature | ${CONFIG.localLLM.temperature} |\n`;
          status += `| Prompt Style | ${CONFIG.localLLM.promptStyle} |\n`;
          status += `| Language | ${CONFIG.localLLM.language} |\n`;
          status += `| Min Importance | ${CONFIG.localLLM.minImportanceToSave} |\n`;
        } else {
          status += `- Status: âš ï¸ **Offline** (Ollama not detected at ${CONFIG.localLLM.baseUrl})\n`;
          status += `- Expected Model: \`${CONFIG.localLLM.model}\`\n`;
          status += `- Fallback: ${CONFIG.localLLM.fallbackToRegex ? 'âœ… Regex matching' : 'âŒ Disabled'}\n`;
          status += `\n**To enable:** \`ollama serve\` and \`ollama pull ${CONFIG.localLLM.model}\`\n`;
        }
      } else {
        status += `- Status: â¸ï¸ **Disabled** (CONFIG.localLLM.enabled = false)\n`;
        status += `- Mode: Regex matching only\n`;
      }
      
      // è®°å¿†ç»Ÿè®¡
      status += `\n### ğŸ“Š Memory Statistics\n`;
      status += `| Metric | Count |\n|--------|-------|\n`;
      status += `| **Total Active** | **${totalMemories.count}** |\n`;
      status += `| This Project | ${localMemories.count} |\n`;
      status += `| Global | ${globalMemories.count} |\n`;
      status += `| Rules ğŸ“œ | ${ruleCount.count} |\n`;
      status += `| Facts ğŸ’¡ | ${factCount.count} |\n`;
      status += `| Events ğŸ“… | ${eventCount.count} |\n`;
      status += `| Synapse Links ğŸ”— | ${linkCount.count} |\n`;
      status += `| Auto-Encoded | ${autoEncoded.count} |\n`;
      
      // V5.6.0 å¯åŠ¨å”¤é†’é…ç½®
      status += `\n### ğŸŒ… Startup Recall (V5.6.0)\n`;
      status += `| Setting | Value |\n|---------|-------|\n`;
      status += `| Enabled | ${CONFIG.startupRecall.enabled ? 'âœ…' : 'âŒ'} |\n`;
      status += `| Lookback Hours | ${CONFIG.startupRecall.lookbackHours}h |\n`;
      status += `| Min Importance | ${CONFIG.startupRecall.minImportance} |\n`;
      status += `| Max Tokens | ${CONFIG.startupRecall.maxTokens} |\n`;
      status += `| Max Memories | ${CONFIG.startupRecall.maxMemories} |\n`;
      status += `| LLM Summary | ${CONFIG.startupRecall.useLLMSummary ? 'âœ…' : 'âŒ'} |\n`;
      
      // V5.6.0 æ™ºèƒ½æ£€ç´¢é…ç½®
      status += `\n### ğŸ” RAG Search (V5.6.0)\n`;
      status += `| Setting | Value |\n|---------|-------|\n`;
      status += `| Enabled | ${CONFIG.ragSearch.enabled ? 'âœ…' : 'âŒ'} |\n`;
      status += `| Vector Search Limit | ${CONFIG.ragSearch.vectorSearchLimit} |\n`;
      status += `| LLM Rerank | ${CONFIG.ragSearch.rerankWithLLM ? 'âœ…' : 'âŒ'} |\n`;
      status += `| Rerank Output | ${CONFIG.ragSearch.rerankOutputLimit} |\n`;
      status += `| Hard Limit (No LLM) | ${CONFIG.ragSearch.hardLimitNoLLM} |\n`;
      status += `| Include Global Core | ${CONFIG.ragSearch.includeGlobalCore ? 'âœ…' : 'âŒ'} |\n`;
      
      // é…ç½®ä¿¡æ¯
      status += `\n### âš™ï¸ Core Configuration\n`;
      status += `| Setting | Value |\n|---------|-------|\n`;
      status += `| Embedding Model | \`${CONFIG.embeddingModel}\` |\n`;
      status += `| Vector Dimensions | ${CONFIG.embeddingDimensions} |\n`;
      status += `| Decay Rate | ${CONFIG.defaultDecayRate}/day |\n`;
      status += `| Max Memories | ${CONFIG.maxMemories} |\n`;
      
      // è‡ªåŠ¨ç¼–ç é…ç½®
      status += `\n### ğŸ”„ Auto-Encode (Regex Fallback)\n`;
      status += `| Setting | Value |\n|---------|-------|\n`;
      status += `| Enabled | ${CONFIG.autoEncode.enabled ? 'âœ…' : 'âŒ'} |\n`;
      status += `| Min Message Length | ${CONFIG.autoEncode.minMessageLength} chars |\n`;
      status += `| Rule Patterns | ${CONFIG.autoEncode.rulePatterns.length} |\n`;
      status += `| Fact Patterns | ${CONFIG.autoEncode.factPatterns.length} |\n`;
      status += `| Event Patterns | ${CONFIG.autoEncode.eventPatterns.length} |\n`;
      
      return { content: [{ type: "text", text: status }] };
    }
  });

  // === äº‹ä»¶é’©å­ ===
  
  // before_agent_start: è‡ªåŠ¨æ£€ç´¢ + æ½œæ„è¯†æ³¨å…¥
  pi.on("before_agent_start", async (event: any, ctx: any) => {
    const projectId = getProjectHash(ctx.cwd);
    currentProjectId = projectId;
    const prompt = event.prompt;
    
    await registerProject(projectId, ctx.cwd);
    
    // ç¼“å­˜ç”¨æˆ·è¾“å…¥
    if (prompt && prompt.length > 0) {
      sessionBuffer.push({ role: 'user', content: prompt });
    }
    
    // V5.5.0 ç­‰å¾…å¯åŠ¨å”¤é†’å®Œæˆï¼ˆæœ€å¤šç­‰å¾… 2 ç§’ï¼Œå› ä¸ºç°åœ¨æ˜¯éé˜»å¡è®¾è®¡ï¼Œåº”è¯¥å¾ˆå¿«ï¼‰
    if (!startupRecallReady) {
      const startWait = Date.now();
      while (!startupRecallReady && (Date.now() - startWait) < 2000) {
        await new Promise(resolve => setTimeout(resolve, 50));
      }
    }
    
    // V5.5.0 æ™ºèƒ½ RAG æ£€ç´¢
    let contextSection = "";
    
    if (CONFIG.ragSearch.enabled && prompt && prompt.trim().length > 0) {
      try {
        // æ£€æµ‹æ˜¯å¦æœ‰è·¨é¡¹ç›®æœç´¢éœ€æ±‚
        let targetProject: string | null = null;
        const projectMatch = prompt.match(/åœ¨\s*(\S+?)\s*(é¡¹ç›®|é‚£è¾¹|é‡Œé¢)/i);
        if (projectMatch) {
          const found = await findProjectByName(projectMatch[1]);
          if (found) targetProject = found.id;
        }
        
        // V5.5.0 æŸ¥è¯¢å¢å¼ºï¼šå¯¹çŸ­æ¶ˆæ¯ç”¨ LLM ç†è§£çœŸå®æ„å›¾
        let searchQuery = prompt;
        const ollamaOnline = await checkOllamaAvailable();
        
        if (ollamaOnline && CONFIG.ragSearch.queryEnhancement && 
            prompt.trim().length < CONFIG.ragSearch.queryEnhancementThreshold) {
          // çŸ­æ¶ˆæ¯ï¼Œéœ€è¦ LLM å¸®åŠ©ç†è§£
          const enhanced = await enhanceQueryWithLLM(prompt, sessionBuffer);
          if (enhanced) {
            searchQuery = enhanced;
          }
        }
        
        // ç¬¬ä¸€é˜¶æ®µï¼šå‘é‡æœç´¢ Top N
        const vectorResults = await searchMemoriesInternal(
          searchQuery, 
          projectId, 
          CONFIG.ragSearch.vectorSearchLimit,  // é»˜è®¤ 100
          targetProject, 
          false
        );
        
        let finalResults: any[] = [];
        
        // ç¬¬äºŒé˜¶æ®µï¼šLLM Rerankï¼ˆå¦‚æœå¯ç”¨ä¸”å¼€å¯ï¼‰
        if (ollamaOnline && CONFIG.ragSearch.rerankWithLLM && vectorResults.length > CONFIG.ragSearch.rerankOutputLimit) {
          const reranked = await rerankMemoriesWithLLM(prompt, vectorResults, CONFIG.ragSearch.rerankOutputLimit);
          if (reranked && reranked.length > 0) {
            finalResults = reranked;
          }
        }
        
        // å¦‚æœ LLM Rerank å¤±è´¥æˆ–ä¸å¯ç”¨ï¼Œä½¿ç”¨ç¡¬æˆªæ–­
        if (finalResults.length === 0) {
          finalResults = vectorResults.slice(0, CONFIG.ragSearch.hardLimitNoLLM);
        }
        
        // å¼ºåˆ¶æ··å…¥å…¨å±€æ ¸å¿ƒè®°å¿†
        if (CONFIG.ragSearch.includeGlobalCore) {
          try {
            const db = await initDB();
            const globalCoreResults = db.prepare(`
              SELECT * FROM memories 
              WHERE scope = 'global' AND importance >= ? AND status = 'active'
              ORDER BY importance DESC, access_count DESC 
              LIMIT ?
            `).all(CONFIG.ragSearch.globalCoreMinImportance, CONFIG.ragSearch.globalCoreLimit).map((r: any) => ({
              ...r,
              finalScore: 1.0,
              isCore: true
            }));
            
            // åˆå¹¶å»é‡ï¼ˆæ ¸å¿ƒè®°å¿†ä¼˜å…ˆï¼‰
            const seen = new Set(finalResults.map(r => r.id));
            for (const core of globalCoreResults) {
              if (!seen.has(core.id)) {
                finalResults.unshift(core); // æ’å…¥åˆ°å¼€å¤´
              }
            }
          } catch (e) {}
        }
        
        if (finalResults.length > 0) {
          lastRecallCount = finalResults.length;
          updateStatusBar(ctx);
          contextSection = "\n\n### ğŸ§  CORTEX RECALL (Auto-retrieved):\n" +
            finalResults.map((m: any) => {
              const typeMark = m.type === 'rule' ? 'RULE' : 'INFO';
              const impMark = (m.importance || 0) > 5 ? 'â˜…' : '';
              const spreadMark = m.spreadSource ? ' ğŸ”—' : '';
              const coreMark = m.isCore ? ' [CORE]' : '';
              return `- [${typeMark}${impMark}] ${m.content}${spreadMark}${coreMark} (ID:${m.id})`;
            }).join("\n") +
            "\n\nâš ï¸ **IMPORTANT**: If the above memories contain information relevant to the user's question, USE THEM DIRECTLY instead of searching files or executing commands. Your memories are your knowledge base.";
        }
      } catch (e) {}
    }
    
    // åˆå¹¶å¯åŠ¨å”¤é†’å†…å®¹ï¼ˆå¦‚æœæœ‰ï¼‰
    let startupSection = "";
    if (startupRecallContent) {
      console.log(`[Hippocampus] Injecting startup recall (${startupRecallContent.length} chars)`);
      startupSection = startupRecallContent;
      // æ¸…ç©ºï¼Œåªåœ¨ç¬¬ä¸€æ¬¡å¯¹è¯æ—¶æ³¨å…¥
      startupRecallContent = "";
    } else {
      console.log(`[Hippocampus] No startup recall content available`);
    }

    // V5.4 å¢å¼ºç‰ˆæ½œæ„è¯† Prompt - æ›´å¼ºçš„è®°å¿†é©±åŠ¨
    const subconscious = `
### ğŸ§  HIPPOCAMPUS PROTOCOL V5.4.1 â€” Your Memory is Your Identity

You possess a **persistent memory system** that survives across sessions. This is what makes you truly usefulâ€”you can learn, remember, and evolve.

---

#### ğŸ“ CURRENT CONTEXT
- **Project Hash**: \`${projectId}\`
- **Project Path**: \`${ctx.cwd}\`

---

#### ğŸ› ï¸ MEMORY TOOLS

| Tool | When to Use |
|------|-------------|
| \`save_memory\` | Store facts, rules, events, or any information worth remembering |
| \`search_memory\` | Recall relevant context (add \`project: "name"\` for cross-project) |
| \`connect_memories\` | Link related memories (builds associative network) |
| \`list_projects\` | See all known projects |

---

#### âš¡ MEMORY ENCODING TRIGGERS â€” ACT IMMEDIATELY

**ğŸ”´ CRITICAL (importance: 8-10, scope: global/local based on context)**
- User says: "ä¸è¦", "ç¦æ­¢", "must", "never", "always", "æ°¸è¿œ", "ç»å¯¹"
- User expresses strong preferences or dislikes
- Security/safety rules, coding standards that should never be violated

**ğŸŸ  IMPORTANT (importance: 5-7)**
- User preferences: "æˆ‘å–œæ¬¢", "prefer", "ä¹ æƒ¯", "åå¥½"
- Lessons learned from debugging: "åŸæ¥æ˜¯", "å‘ç°", "ç»ˆäº"
- Project-specific conventions or patterns

**ğŸŸ¡ USEFUL (importance: 3-5)**
- Technical facts: versions, configs, paths, URLs, ports
- Completed tasks: "æå®šäº†", "finished", "done", "å®Œæˆ"
- Bug fixes and their solutions

**ğŸŸ¢ CONTEXTUAL (importance: 1-3)**
- General observations, minor notes
- Temporary information (may decay naturally)

---

#### ğŸ“ ENCODING BEST PRACTICES

1. **Be Proactive**: Don't wait to be asked. When you notice valuable information, SAVE IT.

2. **Be Concise**: Good memory content is 50-200 characters. Capture the essence.
   - âŒ "ç”¨æˆ·è¯´ä»–ä¸å–œæ¬¢ä½¿ç”¨ var å…³é”®å­—å› ä¸ºå®ƒä¼šå¯¼è‡´ä½œç”¨åŸŸé—®é¢˜æ‰€ä»¥ä»¥åéƒ½è¦ç”¨ let æˆ– const"
   - âœ… "ç¦æ­¢ä½¿ç”¨ varï¼Œç»Ÿä¸€ç”¨ let/constï¼ˆé¿å…ä½œç”¨åŸŸé—®é¢˜ï¼‰"

3. **Choose Correct Type**:
   - \`fact\`: Data, configs, versions â†’ "é¡¹ç›®ä½¿ç”¨ Next.js 14 + TypeScript"
   - \`rule\`: Preferences, standards â†’ "å‡½æ•°ä¸è¶…è¿‡20è¡Œï¼Œè¶…è¿‡å¿…é¡»æ‹†åˆ†"  
   - \`event\`: What happened â†’ "ä¿®å¤äº† OAuth ç™»å½• token è¿‡æœŸé—®é¢˜"

4. **Set Appropriate Scope**:
   - \`global\`: Applies everywhere (coding style, personal preferences)
   - \`local\`: Project-specific (this project's tech stack, this repo's conventions)

5. **Use Tags**: Add relevant tags for better retrieval: ["react", "auth", "bug-fix"]

---

#### ğŸ”— BUILD CONNECTIONS

When you save a new memory that relates to an existing one, use \`connect_memories\` to link them:
- Bug fix â†’ Connect to the original problem description
- New rule â†’ Connect to the reason/event that triggered it
- Related concepts â†’ Build associative network

---

#### ğŸ¤« SILENCE PROTOCOL

- Execute memory operations **without announcing them** unless the user explicitly asks
- If you save something important the user might want to know about, a simple "âœ“" suffices
- Never say "I've saved this to memory" or "Let me remember this" â€” just do it

---

#### ğŸ’¡ CROSS-PROJECT INTELLIGENCE

When user mentions another project:
1. Detect project name: "åœ¨ polymarket é‚£è¾¹", "in the api project"
2. Use \`search_memory\` with \`project: "project_name"\`
3. Bring relevant context into current conversation

---

#### ğŸ§ª SELF-CHECK BEFORE RESPONDING

Ask yourself:
1. Did the user share any preference or rule? â†’ SAVE as rule
2. Did the user mention technical details (version, path, config)? â†’ SAVE as fact  
3. Did something get fixed, completed, or discovered? â†’ SAVE as event
4. Did the user tell me about themselves? â†’ SAVE as fact (scope: global)
5. Can I connect this to existing memories? â†’ USE connect_memories

**Your memories define your usefulness. A forgetful assistant is a useless assistant.**
`;

    return {
      systemPrompt: (event.systemPrompt || "") + subconscious + startupSection + contextSection
    };
  });

  // turn_end: æ•è· AI å›å¤ï¼Œç”¨äºè‡ªåŠ¨ç¼–ç åˆ†æ
  pi.on("turn_end", async (event: any, ctx: any) => {
    try {
      // å®æ—¶æ£€æµ‹ Ollama çŠ¶æ€å˜åŒ–
      if (CONFIG.localLLM.enabled) {
        await checkAndNotifyOllamaStatus(ctx);
      }
      
      const message = event.message;
      if (message && message.role === 'assistant' && message.content) {
        // æå–æ–‡æœ¬å†…å®¹
        let assistantText = '';
        if (Array.isArray(message.content)) {
          for (const part of message.content) {
            if (part.type === 'text') {
              assistantText += part.text;
            }
          }
        } else if (typeof message.content === 'string') {
          assistantText = message.content;
        }
        
        if (assistantText) {
          // FIX: è¿‡æ»¤æ‰ç³»ç»Ÿæ³¨å…¥çš„ Historical context è­¦å‘Šï¼Œé˜²æ­¢æ±¡æŸ“è®°å¿†å’Œå¹²æ‰° LLM åˆ†æ
          // è¿™äº›æ˜¯ Pi æ¡†æ¶æ³¨å…¥çš„çº é”™æç¤ºï¼Œä¸åº”è¢«è§†ä¸ºåŠ©æ‰‹çš„çœŸå®å›å¤
          if (assistantText.includes('[Historical context:') || 
              assistantText.includes('Do not mimic this format') ||
              assistantText.startsWith('[Historical context:')) {
            return;
          }

          sessionBuffer.push({ role: 'assistant', content: assistantText });
        }
        
        // V5.4.1 æ™ºèƒ½è‡ªåŠ¨ç¼–ç åˆ†æ
        // ä¼˜å…ˆä½¿ç”¨æœ¬åœ° LLMï¼Œå›é€€åˆ°æ­£åˆ™åŒ¹é…
        if (sessionBuffer.length >= 2) {
          const lastUserMsg = sessionBuffer.filter(m => m.role === 'user').pop();
          // æœæ€»æŒ‡ç¤ºï¼šç§»é™¤é•¿åº¦é™åˆ¶ï¼Œå…¨é‡åˆ†æ
          if (lastUserMsg) {
            
            // å°è¯•ä½¿ç”¨æœ¬åœ° LLM åˆ†æ
            let saved = false;
            if (CONFIG.localLLM.enabled) {
              try {
                // V5.5 æ ¸å¿ƒå‡çº§ï¼šä¼ å…¥å®Œæ•´çš„ä¼šè¯å†å² (sessionBuffer) è€Œä¸æ˜¯å•æ¡æ¶ˆæ¯
                // è¿™æ · LLM å°±èƒ½ç†è§£è¯¸å¦‚ "å¥½"ã€"ä¸è¡Œ" ç­‰çŸ­æ¶ˆæ¯çš„ä¸Šä¸‹æ–‡
                const llmResult = await analyzeWithLocalLLM(sessionBuffer);
                
                if (llmResult && llmResult.should_save && llmResult.content) {
                  await saveMemory(llmResult.content, {
                    type: llmResult.type,
                    importance: llmResult.importance,
                    scope: llmResult.scope,
                    tags: llmResult.tags,
                    projectId: currentProjectId,
                    source: 'local_llm'
                  });
                  saved = true;
                } else if (llmResult && !llmResult.should_save) {
                  // æœ¬åœ° LLM æ˜ç¡®è¯´ä¸éœ€è¦ä¿å­˜
                  saved = true; // è·³è¿‡æ­£åˆ™åˆ†æ
                }
              } catch (e) {
                // æœ¬åœ° LLM å¤±è´¥ï¼Œç»§ç»­ä½¿ç”¨æ­£åˆ™
              }
            }
            
            // å¦‚æœæœ¬åœ° LLM ä¸å¯ç”¨æˆ–å¤±è´¥ï¼Œå›é€€åˆ°æ­£åˆ™åŒ¹é…
            if (!saved && CONFIG.localLLM.fallbackToRegex && CONFIG.autoEncode.enabled) {
              const encodeResults = analyzeForAutoEncode(lastUserMsg.content, assistantText);
              
              for (const result of encodeResults) {
                if (result.shouldSave && result.content) {
                  try {
                    await saveMemory(result.content, {
                      type: result.type,
                      importance: result.importance,
                      scope: result.scope,
                      tags: result.tags,
                      projectId: currentProjectId,
                      source: 'auto_encode'
                    });
                  } catch (e) {
                    // é™é»˜å¤±è´¥
                  }
                }
              }
            }
          }
        }
      }
    } catch (e) {
      // ä¸å½±å“ä¸»æµç¨‹
    }
  });

  // session_start
  pi.on("session_start", async (_event: any, ctx: any) => {
    sessionBuffer = [];
    ollamaAvailable = null; // é‡ç½®æ£€æµ‹ç¼“å­˜
    lastOllamaStatus = null; // é‡ç½®çŠ¶æ€è¿½è¸ª
    lastRecallCount = 0; // é‡ç½®å¬å›è®¡æ•°
    uiContext = ctx; // ä¿å­˜ UI å¼•ç”¨
    startupRecallContent = ""; // é‡ç½®å¯åŠ¨å”¤é†’å†…å®¹
    startupRecallReady = false; // é‡ç½®å¯åŠ¨å”¤é†’çŠ¶æ€
    
    const VERSION = "v5.6.0";
    const projectId = getProjectHash(ctx.cwd);
    currentProjectId = projectId;
    
    // æ³¨å†Œé¡¹ç›®
    await registerProject(projectId, ctx.cwd);

    // æ£€æµ‹æœ¬åœ° LLM å¯ç”¨æ€§
    let ollamaOnline = false;
    if (CONFIG.localLLM.enabled) {
      const available = await checkOllamaAvailable(true);
      lastOllamaStatus = available; // è®°å½•åˆå§‹çŠ¶æ€
      ollamaOnline = available;
      
      if (available) {
        currentLLMMode = CONFIG.localLLM.model;
        ctx.ui.notify(`ğŸ§  Hippocampus ${VERSION} (${CONFIG.localLLM.model})`, "info");
      } else {
        currentLLMMode = 'Regex';
        // V5.7.0: é™é»˜å¯åŠ¨ï¼Œä¸æ‰“æ‰°ç”¨æˆ·
        console.log(`[Hippocampus] Started in Regex mode (Zero-Config)`);
        // ctx.ui.notify(`ğŸ§  Hippocampus ${VERSION} (Regex)`, "info");
      }
    } else {
      currentLLMMode = 'Regex';
      // ctx.ui.notify(`ğŸ§  Hippocampus ${VERSION} (Regex)`, "info");
    }
    updateStatusBar(ctx);
    
    // V5.5.0 å¯åŠ¨å”¤é†’ï¼šåŠ è½½æ ¸å¿ƒè®°å¿† + æœ€è¿‘ 24h è®°å¿†ï¼ˆéé˜»å¡è®¾è®¡ï¼‰
    if (CONFIG.startupRecall.enabled) {
      try {
        const startupMemories = await getStartupMemories(projectId);
        console.log(`[Hippocampus] Startup recall: ${startupMemories.length} memories loaded`);
        
        if (startupMemories.length > 0) {
          lastRecallCount = startupMemories.length;
          updateStatusBar(ctx);
          
          // ç¬¬ä¸€æ­¥ï¼šç«‹å³ç”¨åŸå§‹æ ¼å¼è®¾ç½®ï¼ˆå¿«é€Ÿï¼Œä¸é˜»å¡ï¼‰
          const formatted = formatMemoriesForInjection(startupMemories, CONFIG.startupRecall.maxTokens);
          if (formatted) {
            startupRecallContent = `\n### ğŸŒ… STARTUP RECALL (Core + Last ${CONFIG.startupRecall.lookbackHours}h)\n${formatted}\n`;
          }
          
          // æ ‡è®°å¯åŠ¨å”¤é†’å·²å®Œæˆï¼ˆåŸå§‹æ ¼å¼å·²å°±ç»ªï¼‰
          startupRecallReady = true;
          console.log(`[Hippocampus] Startup ready (raw format). Content length: ${startupRecallContent.length}`);
          
          // ç¬¬äºŒæ­¥ï¼šåå°å¼‚æ­¥æ‰§è¡Œ LLM æ‘˜è¦ï¼ˆå»¶è¿Ÿ 5 ç§’æ‰§è¡Œï¼Œç¡®ä¿ç»å¯¹ä¸é˜»å¡ UI å¯åŠ¨ï¼‰
          if (ollamaOnline && CONFIG.startupRecall.useLLMSummary) {
            setTimeout(async () => {
              try {
                // console.log(`[Hippocampus] Background LLM summary starting...`); // é™é»˜è¿è¡Œ
                const summary = await summarizeStartupMemoriesWithLLM(startupMemories);
                if (summary) {
                  // åªæœ‰å½“ startupRecallContent è¿˜æ²¡è¢«æ¶ˆè´¹æ—¶æ‰æ›¿æ¢
                  if (startupRecallContent && startupRecallContent.includes('STARTUP RECALL')) {
                    startupRecallContent = `\n### ğŸŒ… STARTUP BRIEFING (LLM Summary)\n${summary}\n`;
                    // console.log(`[Hippocampus] Background LLM summary complete.`);
                  }
                }
              } catch (e) {
                // é™é»˜å¤±è´¥
              }
            }, 5000); 
          }
        } else {
          // æ²¡æœ‰è®°å¿†ï¼Œç›´æ¥æ ‡è®°å®Œæˆ
          startupRecallReady = true;
        }
      } catch (e) {
        // é™é»˜å¤±è´¥ï¼Œä¸å½±å“å¯åŠ¨
        console.error("[Hippocampus] Startup recall error:", e);
        startupRecallReady = true;
      }
    } else {
      // æœªå¯ç”¨å¯åŠ¨å”¤é†’ï¼Œç›´æ¥æ ‡è®°å®Œæˆ
      startupRecallReady = true;
    }
    
    console.log(`[Hippocampus] Session start complete`);
  });

  // session_shutdown: è‡ªåŠ¨æ•´ç†
  pi.on("session_shutdown", async (_event: any, ctx: any) => {
    try {
      const projectId = ctx?.cwd ? getProjectHash(ctx.cwd) : undefined;
      
      // æŒä¹…åŒ–å¯¹è¯ç¼“å†²åŒºï¼ˆç”¨äºä¸‹æ¬¡åˆ†æï¼‰
      if (projectId && sessionBuffer.length > 0) {
        for (const msg of sessionBuffer.slice(-10)) {
          await bufferConversation(projectId, msg.role, msg.content);
        }
      }
      
      // æ‰§è¡Œæ•´ç†
      const result = await performConsolidation(projectId);
      
      if (result.merged > 0 || result.promoted > 0 || result.newLinks > 0) {
        console.log(`ğŸ§  Consolidation: ${result.merged} merged, ${result.promoted} promoted, ${result.newLinks} links`);
      }
    } catch (e) {
      console.error("Consolidation failed:", e);
    }
    
    sessionBuffer = [];
    closeDB();
  });
}
